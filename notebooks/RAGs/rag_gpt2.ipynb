{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTANT\n",
    "\n",
    "#### Due a bug in the mini version of gpt2 I faced some issues with generating the output. This notebook is just for experimentation. The notebook used for the project is rag_llama2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/gold/data.csv')\n",
    "documents = df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'section': 'Overview of This Book',\n",
       " 'text': 'In the first part of this chapter, I’ll walk through the structure of this book. Then, I’ll discuss the various job titles and roles that use ML skills in industry. 1 I’ll also clarify the responsibilities of various job titles, such as data scientist, machine learning engineer, and so on, as this is a common point of confusion for job seekers. These will be illustrated with an ML skills matrix and ML lifecycle that will be referenced throughout the book. The second part of this chapter walks through the interview process, from beginning to end. I’ve mentored candidates who appreciated this overview since online resources often focus on specific pieces of the interview but not how they all connect together and result in an offer. Especially for new graduates 2 and readers coming from different industries, this chapter helps get everyone on the same page as well as clarifies the process. The interconnecting pieces of interviews are complex, with many types of combina‐ tions depending on the ML role you’re aiming for. This overview will help set the stage, so you’ll know what to focus your time on. For example, some online resources focus on knowledge specific to “product data scientists,” but will title the course or article “data scientist interview tips” without differentiating. For a newcomer, it’s hard to tell if that is relevant to your own career interests. After this chapter, you’ll be able to tell what skills are required for each job title, and in Chapter 2 , you’ll be able to parse out that information yourself from job postings and make your resume as relevant to the job title and job posting as possible. This chapter focuses on helping you differentiate among various ML roles, and walks through the entire interview process, as illustrated in Figure 1-1 : • Job applications and resume ( Chapter 2 ) • Technical interviews — Machine learning (Chapters 3 , 4 , and 6 ) — Coding/programming ( Chapter 5 ) • Behavioral interviews ( Chapter 7 ) • Your interview roadmap ( Chapter 8 ) • Post-interview and follow-up ( Chapter 9 ) Figure 1-1. Overview of the chapters and how they tie into the ML interview process. Depending on where you are in your ML interview journey, I encourage you to focus on the chapters and sections that seem relevant to you. I’ve also planned the book to be referenced as you go along; for example, you might iterate on your resume multi‐ ple times and then flip back to Chapter 2 when needed. The same applies to the other chapters. With that overview, let’s continue. The companion site to this book, https://susanshu.substack.com , features bonus content, helper resources, and more.',\n",
       " 'text_id': '86fd49a66d'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into chunks/sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"es_core_news_sm\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_sentence_chunks(text, base_id):\n",
    "    doc = nlp(text)  \n",
    "    sentences = [sent.text for sent in doc.sents] \n",
    "\n",
    "    chunked_texts = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        current_chunk.append(sentence)\n",
    "\n",
    "        if len(current_chunk) >= 3:  \n",
    "            chunked_texts.append(' '.join(current_chunk))\n",
    "            current_chunk = []  \n",
    "\n",
    "    if current_chunk:\n",
    "        chunked_texts.append(' '.join(current_chunk))\n",
    "\n",
    "    chunk_ids = [f\"{base_id}_{i + 1}\" for i in range(len(chunked_texts))]\n",
    "\n",
    "    return [{'chunk_id': chunk_id, 'chunk_text': chunk_text, 'text_id': base_id} \n",
    "            for chunk_id, chunk_text in zip(chunk_ids, chunked_texts)]\n",
    "\n",
    "chunked_docs = []\n",
    "for doc in documents:\n",
    "    if 'text' in doc and 'text_id' in doc:  \n",
    "        chunks = split_into_sentence_chunks(doc['text'], doc['text_id'])\n",
    "        chunked_docs.extend(chunks)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'chunk_id': '86fd49a66d_1',\n",
       "  'chunk_text': 'In the first part of this chapter, I’ll walk through the structure of this book. Then, I’ll discuss the various job titles and roles that use ML skills in industry. 1 I’ll also clarify the responsibilities of various job titles, such as data scientist, machine learning engineer, and so on, as this is a common point of confusion for job seekers.',\n",
       "  'text_id': '86fd49a66d'},\n",
       " {'chunk_id': '86fd49a66d_2',\n",
       "  'chunk_text': 'These will be illustrated with an ML skills matrix and ML lifecycle that will be referenced throughout the book. The second part of this chapter walks through the interview process, from beginning to end. I’ve mentored candidates who appreciated this overview since online resources often focus on specific pieces of the interview but not how they all connect together and result in an offer.',\n",
       "  'text_id': '86fd49a66d'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_docs[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minsearch import Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.minsearch.Index at 0x79cea59cf2e0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = Index(\n",
    "    text_fields=[ \"chunk_text\"],\n",
    "    keyword_fields=[\"text_id\", \"chunk_id\"]\n",
    ")\n",
    "\n",
    "\n",
    "index.fit(chunked_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'chunk_id': '6d22154063_1',\n",
       "  'chunk_text': 'Here is a nonexhaustive list of job titles for ML (or closely related) roles: • Data scientist • Machine learning engineer • Applied scientist • Software engineer, machine learning • MLOps engineer • Product data scientist • Data analyst • Decision scientist • Research scientist As I discussed “A Brief History of Machine Learning and Data Science Job Titles” on page 3 , each role is responsible for a different part of the ML lifecycle. A job title alone does not convey what the job entails. As a job seeker, be warned: in different companies, completely different titles might end up doing similar jobs!',\n",
       "  'text_id': '6d22154063'},\n",
       " {'chunk_id': '6d22154063_2',\n",
       "  'chunk_text': 'As illustrated in Figure 1-3 , your ML job title will depend on the company, the team, and which part(s) of the ML lifecycle your role is responsible for. To give specific examples of how job titles can depend on the company or organiza‐ tion that is hiring for the job—based on real people I’ve spoken to, job descriptions, and job interviews—the person responsible for training ML models but not for build‐ ing the underlying platform might be called the following: • Software engineer (ML) or data scientist (Google) • Applied scientist (Amazon) • Machine learning engineer (Meta, Pinterest) • Data scientist (Elastic, the team where I work) • Data scientist (Unity) Figure 1-3. What’s in a machine learning job title?',\n",
       "  'text_id': '6d22154063'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'what is the scope of a data scientist?'\n",
    "\n",
    "def search(query):\n",
    "    boost = {}\n",
    "    # boost = {'text': 3.0, 'section': 0.5}\n",
    "    \n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict = {},\n",
    "        boost_dict=boost,\n",
    "        num_results=2\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "search_results = search(query)\n",
    "search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x79cfc9f51770>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" \n",
    "\n",
    "torch.random.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are an assistant preparing a candidate for a data science interview. \n",
    "Based on the provided context, please provide a concise and accurate answer to the following question in plain text format without any additional formatting.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Here is a nonexhaustive list of job titles for ML (or closely related) roles: • Data scientist • Machine learning engineer • Applied scientist • Software engineer, machine learning • MLOps engineer • Product data scientist • Data analyst • Decision scientist • Research scientist As I discussed “A Brief History of Machine Learning and Data Science Job Titles” on page 3 , each role is responsible for a different part of the ML lifecycle. A job title alone does not convey what the job entails. As a job seeker, be warned: in different companies, completely different titles might end up doing similar jobs!\n",
      "\n",
      "Text: As illustrated in Figure 1-3 , your ML job title will depend on the company, the team, and which part(s) of the ML lifecycle your role is responsible for. To give specific examples of how job titles can depend on the company or organiza‐ tion that is hiring for the job—based on real people I’ve spoken to, job descriptions, and job interviews—the person responsible for training ML models but not for build‐ ing the underlying platform might be called the following: • Software engineer (ML) or data scientist (Google) • Applied scientist (Amazon) • Machine learning engineer (Meta, Pinterest) • Data scientist (Elastic, the team where I work) • Data scientist (Unity) Figure 1-3. What’s in a machine learning job title?\n"
     ]
    }
   ],
   "source": [
    "# def build_context(search_results):\n",
    "#     context = []\n",
    "    \n",
    "#     for result in search_results:\n",
    "#         text = result.get(\"chunk_text\", \"\")\n",
    "        \n",
    "#         context.append(f\"Text: {text}\")\n",
    "    \n",
    "#     return \"\\n\\n\".join(context)\n",
    "\n",
    "# context = build_context(search_results)\n",
    "# print(context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant preparing a candidate for a data science interview. \n",
      "Based on the provided context, please provide a concise and accurate answer to the following question in plain text format without any additional formatting.\n",
      "\n",
      "QUESTION: what is the scope of a data scientist?\n",
      "\n",
      "CONTEXT:\n",
      "Text: Here is a nonexhaustive list of job titles for ML (or closely related) roles: • Data scientist • Machine learning engineer • Applied scientist • Software engineer, machine learning • MLOps engineer • Product data scientist • Data analyst • Decision scientist • Research scientist As I discussed “A Brief History of Machine Learning and Data Science Job Titles” on page 3 , each role is responsible for a different part of the ML lifecycle. A job title alone does not convey what the job entails. As a job seeker, be warned: in different companies, completely different titles might end up doing similar jobs!\n",
      "\n",
      "Text: As illustrated in Figure 1-3 , your ML job title will depend on the company, the team, and which part(s) of the ML lifecycle your role is responsible for. To give specific examples of how job titles can depend on the company or organiza‐ tion that is hiring for the job—based on real people I’ve spoken to, job descriptions, and job interviews—the person responsible for training ML models but not for build‐ ing the underlying platform might be called the following: • Software engineer (ML) or data scientist (Google) • Applied scientist (Amazon) • Machine learning engineer (Meta, Pinterest) • Data scientist (Elastic, the team where I work) • Data scientist (Unity) Figure 1-3. What’s in a machine learning job title?\n"
     ]
    }
   ],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        text = doc['chunk_text']\n",
    "            \n",
    "        context += f\"Text: {text}\\n\\n\"\n",
    "\n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "prompt = build_prompt(query, search_results)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors='pt', truncation=True,  max_length=1000)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, pad_token_id=tokenizer.eos_token_id, num_return_sequences=1,max_new_tokens=50) \n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)    \n",
    "    answer = llm(prompt)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant preparing a candidate for a data science interview. \n",
      "Based on the provided context, please provide a concise and accurate answer to the following question in plain text format without any additional formatting.\n",
      "\n",
      "QUESTION: what is the scope of a data scientist?\n",
      "\n",
      "CONTEXT:\n",
      "Text: Here is a nonexhaustive list of job titles for ML (or closely related) roles: • Data scientist • Machine learning engineer • Applied scientist • Software engineer, machine learning • MLOps engineer • Product data scientist • Data analyst • Decision scientist • Research scientist As I discussed “A Brief History of Machine Learning and Data Science Job Titles” on page 3 , each role is responsible for a different part of the ML lifecycle. A job title alone does not convey what the job entails. As a job seeker, be warned: in different companies, completely different titles might end up doing similar jobs!\n",
      "\n",
      "Text: As illustrated in Figure 1-3 , your ML job title will depend on the company, the team, and which part(s) of the ML lifecycle your role is responsible for. To give specific examples of how job titles can depend on the company or organiza‐ tion that is hiring for the job—based on real people I’ve spoken to, job descriptions, and job interviews—the person responsible for training ML models but not for build‐ ing the underlying platform might be called the following: • Software engineer (ML) or data scientist (Google) • Applied scientist (Amazon) • Machine learning engineer (Meta, Pinterest) • Data scientist (Elastic, the team where I work) • Data scientist (Unity) Figure 1-3. What’s in a machine learning job title?\n",
      "QUESTION: What is the scope of a data scientist?\n",
      "CONTEXT:\n",
      "Text: Here is a nonexhaustive list of job titles for ML (or closely related) roles: • Data scientist • Machine learning engineer • Machine learning engineer\n"
     ]
    }
   ],
   "source": [
    "print(rag(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions = pd.read_csv('../data/ground_truth_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = df_questions.to_dict(orient = 'records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_search(query):\n",
    "    boost = {}\n",
    "    # boost = {'text': 3.0, 'section': 0.5}\n",
    "    \n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict = {},\n",
    "        boost_dict=boost,\n",
    "        num_results=2\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['document']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(ground_truth, lambda q: minsearch_search(q['question']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(ground_truth, lambda q: minsearch_search(q['question']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparams Optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df_questions[:100]\n",
    "df_test = df_questions[100:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "# Espacio de búsqueda para Hyperopt\n",
    "space = {\n",
    "    'temperature': hp.uniform('temperature', 0.5, 1.5),  # Ajuste de temperatura\n",
    "    'max_new_tokens': hp.choice('max_new_tokens', [20, 50, 100]),  # Límite de tokens generados\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    temperature = params['temperature']\n",
    "    max_new_tokens = params['max_new_tokens']\n",
    "\n",
    "    # Configurar el modelo con los parametros de arriba que faltan eh?\n",
    "    output_tokens = model.generate(\n",
    "        **inputs, \n",
    "        pad_token_id=tokenizer.eos_token_id, num_return_sequences=num_return_sequences,max_new_tokens=max_new_tokens) \n",
    "    )\n",
    "    \n",
    "    generated_text = tokenizer.decode(output_tokens[0], skip_special_tokens=True).strip()\n",
    "\n",
    "    # Evaluar la calidad del texto generado con las métricas definidas\n",
    "    # Asumamos que tienes una función calculate_mrr que recibe las predicciones y el ground truth\n",
    "    mrr_score = mrr(generated_text)\n",
    "    \n",
    "    # Devuelve la métrica negativa para que Hyperopt lo minimice\n",
    "    return {'loss': -mrr_score, 'status': 'ok'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "# Inicializar el historial de pruebas\n",
    "trials = Trials()\n",
    "\n",
    "# Ejecutar la búsqueda\n",
    "best = fmin(\n",
    "    fn=objective,  # Función objetivo\n",
    "    space=space,  # Espacio de búsqueda\n",
    "    algo=tpe.suggest,  # Algoritmo de optimización\n",
    "    max_evals=10,  # Número de evaluaciones\n",
    "    trials=trials  # Historial de pruebas\n",
    ")\n",
    "\n",
    "print(\"Mejores hiperparámetros encontrados:\", best)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_val = df_val.dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(gt_val, lambda q: minsearch_search(q['question']))\n",
    "# para mirar cuanto da con los mejores hyperparam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_search_optimized(query):\n",
    "    # boost = {'text': 3.0, 'section': 0.5} AQUI VAN LOS HYPERPARAMS \n",
    "    \n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict = {},\n",
    "        boost_dict=boost,\n",
    "        num_results=2\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(ground_truth, lambda q: minsearch_search_optimized(q['question']))\n",
    "#copiar y pegar en el README\n",
    "# tb los best boosting params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1_template = \"\"\"\n",
    "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
    "Your task is to analyze the relevance of the generated answer compared to the original answer provided.\n",
    "Based on the relevance and similarity of the generated answer to the original answer, you will classify\n",
    "it as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Original Answer: {answer_orig}\n",
    "Generated Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the original\n",
    "answer and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()\n",
    "\n",
    "prompt2_template = \"\"\"\n",
    "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
    "Your task is to analyze the relevance of the generated answer to the given question.\n",
    "Based on the relevance of the generated answer, you will classify it\n",
    "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the question\n",
    "and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ground_truth) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interview_preparation_bot-ZQDkHgpI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
