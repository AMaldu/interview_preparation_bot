{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval approach with Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='tqdm')\n",
    "\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained Model used for creation of embeddings\n",
    "\n",
    "The model used to create the embeddings can be found in this website\n",
    "https://www.sbert.net/docs/sentence_transformer/pretrained_models.html#semantic-search-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maldu/.local/share/virtualenvs/interview_preparation_bot-ZQDkHgpI/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output of the model has 768 dimensional embeddings\n"
     ]
    }
   ],
   "source": [
    "print(f'The output of the model has {len(model.encode(\"How many features or dimensions the model uses to represent the input text?\"))} dimensional embeddings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flattening the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/documents_with_ids.json', 'rt') as f_in:\n",
    "    documents = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chapter': 'CHAPTER 1',\n",
       " 'title': 'Machine Learning Roles and the Interview Process',\n",
       " 'section': 'Overview of This Book',\n",
       " 'text': 'In the first part of this chapter, I’ll walk through the structure of this book. Then, I’ll discuss the various job titles and roles that use ML skills in industry. 1 I’ll also clarify the responsibilities of various job titles, such as data scientist, machine learning engineer, and so on, as this is a common point of confusion for job seekers. These will be illustrated with an ML skills matrix and ML lifecycle that will be referenced throughout the book. The second part of this chapter walks through the interview process, from beginning to end. I’ve mentored candidates who appreciated this overview since online resources often focus on specific pieces of the interview but not how they all connect together and result in an offer. Especially for new graduates 2 and readers coming from different industries, this chapter helps get everyone on the same page as well as clarifies the process. The interconnecting pieces of interviews are complex, with many types of combina‐ tions depending on the ML role you’re aiming for. This overview will help set the stage, so you’ll know what to focus your time on. For example, some online resources focus on knowledge specific to “product data scientists,” but will title the course or article “data scientist interview tips” without differentiating. For a newcomer, it’s hard to tell if that is relevant to your own career interests. After this chapter, you’ll be able to tell what skills are required for each job title, and in Chapter 2 , you’ll be able to parse out that information yourself from job postings and make your resume as relevant to the job title and job posting as possible. This chapter focuses on helping you differentiate among various ML roles, and walks through the entire interview process, as illustrated in Figure 1-1 : • Job applications and resume ( Chapter 2 ) • Technical interviews — Machine learning (Chapters 3 , 4 , and 6 ) — Coding/programming ( Chapter 5 ) • Behavioral interviews ( Chapter 7 ) • Your interview roadmap ( Chapter 8 ) • Post-interview and follow-up ( Chapter 9 ) Figure 1-1. Overview of the chapters and how they tie into the ML interview process. Depending on where you are in your ML interview journey, I encourage you to focus on the chapters and sections that seem relevant to you. I’ve also planned the book to be referenced as you go along; for example, you might iterate on your resume multi‐ ple times and then flip back to Chapter 2 when needed. The same applies to the other chapters. With that overview, let’s continue. The companion site to this book, https://susanshu.substack.com , features bonus content, helper resources, and more.',\n",
       " 'id': '86fd49a66d'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents = []\n",
    "\n",
    "# for chapter in book_raw:\n",
    "#     chapter_name = chapter['chapter']\n",
    "#     title = chapter['title']\n",
    "\n",
    "#     for doc in chapter['content']:\n",
    "#         new_doc = {\n",
    "#             'chapter': chapter_name,\n",
    "#             'title': title,\n",
    "#             'section': doc['section'],\n",
    "#             'text': doc['text']\n",
    "#         }\n",
    "#         documents.append(new_doc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chapter': 'CHAPTER 1',\n",
       " 'title': 'Machine Learning Roles and the Interview Process',\n",
       " 'section': 'Overview of This Book',\n",
       " 'text': 'In the first part of this chapter, I’ll walk through the structure of this book. Then, I’ll discuss the various job titles and roles that use ML skills in industry. 1 I’ll also clarify the responsibilities of various job titles, such as data scientist, machine learning engineer, and so on, as this is a common point of confusion for job seekers. These will be illustrated with an ML skills matrix and ML lifecycle that will be referenced throughout the book. The second part of this chapter walks through the interview process, from beginning to end. I’ve mentored candidates who appreciated this overview since online resources often focus on specific pieces of the interview but not how they all connect together and result in an offer. Especially for new graduates 2 and readers coming from different industries, this chapter helps get everyone on the same page as well as clarifies the process. The interconnecting pieces of interviews are complex, with many types of combina‐ tions depending on the ML role you’re aiming for. This overview will help set the stage, so you’ll know what to focus your time on. For example, some online resources focus on knowledge specific to “product data scientists,” but will title the course or article “data scientist interview tips” without differentiating. For a newcomer, it’s hard to tell if that is relevant to your own career interests. After this chapter, you’ll be able to tell what skills are required for each job title, and in Chapter 2 , you’ll be able to parse out that information yourself from job postings and make your resume as relevant to the job title and job posting as possible. This chapter focuses on helping you differentiate among various ML roles, and walks through the entire interview process, as illustrated in Figure 1-1 : • Job applications and resume ( Chapter 2 ) • Technical interviews — Machine learning (Chapters 3 , 4 , and 6 ) — Coding/programming ( Chapter 5 ) • Behavioral interviews ( Chapter 7 ) • Your interview roadmap ( Chapter 8 ) • Post-interview and follow-up ( Chapter 9 ) Figure 1-1. Overview of the chapters and how they tie into the ML interview process. Depending on where you are in your ML interview journey, I encourage you to focus on the chapters and sections that seem relevant to you. I’ve also planned the book to be referenced as you go along; for example, you might iterate on your resume multi‐ ple times and then flip back to Chapter 2 when needed. The same applies to the other chapters. With that overview, let’s continue. The companion site to this book, https://susanshu.substack.com , features bonus content, helper resources, and more.',\n",
       " 'id': '86fd49a66d'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Elasticsearch connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run on the console\n",
    "\n",
    "sudo docker run -it \\\n",
    "    --rm \\\n",
    "    --name elasticsearch \\\n",
    "    -m 4GB \\\n",
    "    -p 9200:9200 \\\n",
    "    -p 9300:9300 \\\n",
    "    -e \"discovery.type=single-node\" \\\n",
    "    -e \"xpack.security.enabled=false\" \\\n",
    "    docker.elastic.co/elasticsearch/elasticsearch:8.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': 'c50174f412e8', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'kvwQsZSrSda4KM_lcgzmPw', 'version': {'number': '8.4.3', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '42f05b9372a9a4a470db3b52817899b99a76ee73', 'build_date': '2022-10-04T07:17:24.662462378Z', 'build_snapshot': False, 'lucene_version': '9.3.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "es_client = Elasticsearch('http://localhost:9200') \n",
    "\n",
    "es_client.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create mappings and Index\n",
    "\n",
    "Imagine that you need to create a schema. what do you need? I would say the column names, the table name, the type of data you are going to introduce...\n",
    "\n",
    "The mapping will set this metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0,\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\n",
    "                \"standard_analyzer\": {\n",
    "                \"type\": \"standard\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "    \"properties\": {\n",
    "        \"text\": {\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"standard_analyzer\"  \n",
    "        },\n",
    "        \"section\": {\n",
    "            \"type\": \"keyword\",\n",
    "        },\n",
    "        \"chapter\": {\n",
    "            \"type\": \"keyword\",\n",
    "        },\n",
    "        \"title\": {\n",
    "            \"type\": \"keyword\",\n",
    "        },\n",
    "        \"text_vector\": {\n",
    "            \"type\": \"dense_vector\",\n",
    "            \"dims\": 768, # got them above\n",
    "            \"index\": True,\n",
    "            \"similarity\": \"cosine\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'ds-interview-questions'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"ds-interview-questions\"\n",
    "\n",
    "# it is better to delete the index every time when experimenting\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True) \n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add documents to the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    try:\n",
    "        es_client.index(index=index_name, body=doc)\n",
    "    except Exception as e:\n",
    "        print(f\"Error when indexing the document: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create user query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = \"which are the steps of the data science interview process?\"\n",
    "vector_search_term = model.encode(search_term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_search(query, index=index_name):\n",
    "    \"\"\"\n",
    "    Execute a search query on the specified index.\n",
    "\n",
    "    Parameters:\n",
    "        query (dict): The search query to execute.\n",
    "        index (str): The name of the index to search.\n",
    "\n",
    "    Returns:\n",
    "        None: Prints the search results.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = es_client.search(index=index, body=query)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error during search: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full-text search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_text_search(search_term):\n",
    "    full_text_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": [\n",
    "                    {\n",
    "                        \"match\": {\n",
    "                            \"text\": {\n",
    "                                \"query\": search_term,\n",
    "                                \"boost\": 1.0\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"multi_match\": {\n",
    "                            \"query\": search_term,\n",
    "                            \"fields\": [\"text^2\", \"section\", \"title\"],\n",
    "                            \"type\": \"best_fields\"\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "                \"should\": [\n",
    "                    {\n",
    "                        \"terms\": {\n",
    "                            \"title\": [\"technical\", \"behavioral\"]\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    full_text_results = execute_search(full_text_query)\n",
    "    return full_text_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Text Search Results:\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull Text Search Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mfull_text_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearch_term\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhits\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhits\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(\"Full Text Search Results:\")\n",
    "print(full_text_search(search_term)['hits']['hits'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the dense vector using the pre-trained model\n",
    "\n",
    "A dense vector typically represents a word, sentence, or document as a fixed-length array of numbers, also known as an embedding. Dense vectors are crucial for Elasticsearch, when we want to perform tasks where understanding the meaning behind the words is more important than just matching exact terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "operations = []\n",
    "for doc in documents:\n",
    "    doc[\"text_vector\"] = model.encode(doc[\"text\"]).tolist()\n",
    "    operations.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operations[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add documents to the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in operations:\n",
    "    try:\n",
    "        es_client.index(index=index_name, body=doc)\n",
    "    except Exception as e:\n",
    "        print(f\"Error when indexing the document: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(vector_search_term):\n",
    "    semantic_query = {\n",
    "    \"size\": 5,\n",
    "    \"knn\": {\n",
    "        \"field\": \"text_vector\",\n",
    "        \"query_vector\": vector_search_term,\n",
    "        \"k\": 3,  \n",
    "        \"num_candidates\": 1000  \n",
    "    },\n",
    "    \"_source\": [\"text\", \"section\", \"title\"] \n",
    "    }\n",
    "\n",
    "    semantic_results = execute_search(semantic_query)\n",
    "    return semantic_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSemantic Search Results:\")\n",
    "print(semantic_search(vector_search_term)['hits']['hits'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Search\n",
    "\n",
    "Combination of both full-text and vector search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_search(search_term):\n",
    "    text_vector_query = {\n",
    "    \"size\": 5,\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                {\n",
    "                    \"match\": {\n",
    "                        \"text\": {\n",
    "                            \"query\": search_term,\n",
    "                            \"boost\": 1.0\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": search_term,\n",
    "                        \"fields\": [\"text^2\", \"section\", \"title\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "            \"should\": [\n",
    "                {\n",
    "                    \"terms\": {\n",
    "                        \"title\": [\"technical\", \"behavioral\"]\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"knn\": {\n",
    "        \"field\": \"text_vector\",\n",
    "        \"query_vector\": vector_search_term,\n",
    "        \"k\": 3,\n",
    "        \"num_candidates\": 1000\n",
    "    }\n",
    "    }\n",
    "\n",
    "    text_vector_results = execute_search(text_vector_query)\n",
    "    text_vector_results['hits']['hits'][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df = pd.read_csv('../../data/ground_truth_data.csv')\n",
    "gt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth =  gt_df.to_dict(orient ='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for question in ground_truth:\n",
    "    search_term = question['question']\n",
    "    doc_id = question['text_id']\n",
    "    text_results = execute_search(full_text_query)\n",
    "    text_results\n",
    "    relevance = [doc['id'] == doc_id for doc in text_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_search(results, gt_df):\n",
    "    evaluations = {}\n",
    "    \n",
    "    for index, row in gt_df.iterrows():\n",
    "        search_term = row['question']  \n",
    "        expected_answers = set(row['expected_answers']) if 'expected_answers' in row else set()  \n",
    "\n",
    "        # Get the actual results for the current search term\n",
    "        actual_full_text_set = set(doc['_source']['title'] for doc in results[search_term]['full_text'])\n",
    "        actual_semantic_set = set(doc['_source']['title'] for doc in results[search_term]['semantic'])\n",
    "        actual_text_vector_set = set(doc['_source']['title'] for doc in results[search_term]['text_vector'])\n",
    "\n",
    "        # Calculate precision, recall, and F1 score for full text search\n",
    "        precision_full_text = precision_score(list(expected_answers), list(actual_full_text_set), average='binary', zero_division=0)\n",
    "        recall_full_text = recall_score(list(expected_answers), list(actual_full_text_set), average='binary', zero_division=0)\n",
    "        f1_full_text = f1_score(list(expected_answers), list(actual_full_text_set), average='binary', zero_division=0)\n",
    "        \n",
    "        # Repeat for semantic search\n",
    "        precision_semantic = precision_score(list(expected_answers), list(actual_semantic_set), average='binary', zero_division=0)\n",
    "        recall_semantic = recall_score(list(expected_answers), list(actual_semantic_set), average='binary', zero_division=0)\n",
    "        f1_semantic = f1_score(list(expected_answers), list(actual_semantic_set), average='binary', zero_division=0)\n",
    "\n",
    "        # Repeat for text vector search\n",
    "        precision_vector = precision_score(list(expected_answers), list(actual_text_vector_set), average='binary', zero_division=0)\n",
    "        recall_vector = recall_score(list(expected_answers), list(actual_text_vector_set), average='binary', zero_division=0)\n",
    "        f1_vector = f1_score(list(expected_answers), list(actual_text_vector_set), average='binary', zero_division=0)\n",
    "\n",
    "        evaluations[search_term] = {\n",
    "            'full_text': {\n",
    "                'precision': precision_full_text,\n",
    "                'recall': recall_full_text,\n",
    "                'f1': f1_full_text\n",
    "            },\n",
    "            'semantic': {\n",
    "                'precision': precision_semantic,\n",
    "                'recall': recall_semantic,\n",
    "                'f1': f1_semantic\n",
    "            },\n",
    "            'vector': {\n",
    "                'precision': precision_vector,\n",
    "                'recall': recall_vector,\n",
    "                'f1': f1_vector\n",
    "            }\n",
    "        }\n",
    "\n",
    "    return evaluations\n",
    "\n",
    "evaluation_results = evaluate_search(results, gt_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interview_preparation_bot-ZQDkHgpI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
