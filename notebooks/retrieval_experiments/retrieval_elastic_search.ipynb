{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval approach with Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='tqdm')\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained Model used for creation of embeddings\n",
    "\n",
    "The model used to create the embeddings can be found in this website\n",
    "https://www.sbert.net/docs/sentence_transformer/pretrained_models.html#semantic-search-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output of the model has 768 dimensional embeddings\n"
     ]
    }
   ],
   "source": [
    "print(f'The output of the model has {len(model.encode(\"How many features or dimensions the model uses to represent the input text?\"))} dimensional embeddings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/documents_with_ids.json', 'rt') as f_in:\n",
    "    documents = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chapter': 'CHAPTER 1',\n",
       " 'title': 'Machine Learning Roles and the Interview Process',\n",
       " 'section': 'Overview of This Book',\n",
       " 'text': 'In the first part of this chapter, I’ll walk through the structure of this book. Then, I’ll discuss the various job titles and roles that use ML skills in industry. 1 I’ll also clarify the responsibilities of various job titles, such as data scientist, machine learning engineer, and so on, as this is a common point of confusion for job seekers. These will be illustrated with an ML skills matrix and ML lifecycle that will be referenced throughout the book. The second part of this chapter walks through the interview process, from beginning to end. I’ve mentored candidates who appreciated this overview since online resources often focus on specific pieces of the interview but not how they all connect together and result in an offer. Especially for new graduates 2 and readers coming from different industries, this chapter helps get everyone on the same page as well as clarifies the process. The interconnecting pieces of interviews are complex, with many types of combina‐ tions depending on the ML role you’re aiming for. This overview will help set the stage, so you’ll know what to focus your time on. For example, some online resources focus on knowledge specific to “product data scientists,” but will title the course or article “data scientist interview tips” without differentiating. For a newcomer, it’s hard to tell if that is relevant to your own career interests. After this chapter, you’ll be able to tell what skills are required for each job title, and in Chapter 2 , you’ll be able to parse out that information yourself from job postings and make your resume as relevant to the job title and job posting as possible. This chapter focuses on helping you differentiate among various ML roles, and walks through the entire interview process, as illustrated in Figure 1-1 : • Job applications and resume ( Chapter 2 ) • Technical interviews — Machine learning (Chapters 3 , 4 , and 6 ) — Coding/programming ( Chapter 5 ) • Behavioral interviews ( Chapter 7 ) • Your interview roadmap ( Chapter 8 ) • Post-interview and follow-up ( Chapter 9 ) Figure 1-1. Overview of the chapters and how they tie into the ML interview process. Depending on where you are in your ML interview journey, I encourage you to focus on the chapters and sections that seem relevant to you. I’ve also planned the book to be referenced as you go along; for example, you might iterate on your resume multi‐ ple times and then flip back to Chapter 2 when needed. The same applies to the other chapters. With that overview, let’s continue. The companion site to this book, https://susanshu.substack.com , features bonus content, helper resources, and more.',\n",
       " 'id': '86fd49a66d'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents = []\n",
    "\n",
    "# for chapter in book_raw:\n",
    "#     chapter_name = chapter['chapter']\n",
    "#     title = chapter['title']\n",
    "\n",
    "#     for doc in chapter['content']:\n",
    "#         new_doc = {\n",
    "#             'chapter': chapter_name,\n",
    "#             'title': title,\n",
    "#             'section': doc['section'],\n",
    "#             'text': doc['text']\n",
    "#         }\n",
    "#         documents.append(new_doc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Elasticsearch connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO - docker config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run on the console (linux)\n",
    "\n",
    "sudo docker run -it \\\n",
    "    --rm \\\n",
    "    --name elasticsearch \\\n",
    "    -m 4GB \\\n",
    "    -p 9200:9200 \\\n",
    "    -p 9300:9300 \\\n",
    "    -e \"discovery.type=single-node\" \\\n",
    "    -e \"xpack.security.enabled=false\" \\\n",
    "    docker.elastic.co/elasticsearch/elasticsearch:8.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': '0c3b70f23821', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'l4X7MPHXRhqR6jR-CbMxdw', 'version': {'number': '8.4.3', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '42f05b9372a9a4a470db3b52817899b99a76ee73', 'build_date': '2022-10-04T07:17:24.662462378Z', 'build_snapshot': False, 'lucene_version': '9.3.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "es_client = Elasticsearch('http://localhost:9200') \n",
    "\n",
    "es_client.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create mappings and Index\n",
    "\n",
    "Imagine that you need to create a schema. what do you need? I would say the column names, the table name, the type of data you are going to introduce...\n",
    "\n",
    "The mapping will set this metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0,\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\n",
    "                \"standard_analyzer\": {\n",
    "                \"type\": \"standard\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "    \"properties\": {        \n",
    "        \"chapter\": {\n",
    "            \"type\": \"text\",\n",
    "        },\n",
    "        \"title\": {\n",
    "            \"type\": \"text\",\n",
    "        },\n",
    "        \"section\": {\n",
    "            \"type\": \"text\",\n",
    "        },\n",
    "        \"text\": {\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"standard_analyzer\"  \n",
    "        },\n",
    "        \"id\":{\n",
    "            \"type\": \"keyword\",\n",
    "        },\n",
    "        \"text_vector\": {\n",
    "            \"type\": \"dense_vector\",\n",
    "            \"dims\": 768, # got them above\n",
    "            \"index\": True,\n",
    "            \"similarity\": \"cosine\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'ds-interview-questions'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"ds-interview-questions\"\n",
    "\n",
    "# it is better to delete the index every time when experimenting\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True) \n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add documents to the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898768e1c0bf44a5895c015406982da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    try:\n",
    "        es_client.index(index=index_name, document=doc)\n",
    "    except Exception as e:\n",
    "        print(f\"Error when indexing the document: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create user query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = \"which are the steps of the data science interview process?\"\n",
    "vector_search_term = model.encode(search_term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_search(query, index=index_name):\n",
    "    \"\"\"\n",
    "    Execute a search query on the specified index.\n",
    "\n",
    "    Parameters:\n",
    "        query (dict): The search query to execute.\n",
    "        index (str): The name of the index to search.\n",
    "\n",
    "    Returns:\n",
    "        None: Prints the search results.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = es_client.search(index=index, body=query)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error during search: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full-text search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_text_search(search_term):\n",
    "    full_text_query = {\n",
    "        \"size\": 15,\n",
    "        \"query\": {\n",
    "            \"multi_match\": {\n",
    "                \"query\": search_term,\n",
    "                \"fields\": [\"text^3\", \"section\", \"title\"],\n",
    "                \"type\": \"best_fields\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    full_text_results = execute_search(full_text_query)\n",
    "\n",
    "    return full_text_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Full Text Search Results:\")\n",
    "# print(full_text_search(search_term)['hits']['hits'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the dense vector using the pre-trained model\n",
    "\n",
    "A dense vector typically represents a word, sentence, or document as a fixed-length array of numbers, also known as an embedding. Dense vectors are crucial for Elasticsearch, when we want to perform tasks where understanding the meaning behind the words is more important than just matching exact terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "operations = []\n",
    "for doc in documents:\n",
    "    doc[\"text_vector\"] = model.encode(doc[\"text\"]).tolist()\n",
    "    operations.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chapter': 'CHAPTER 1',\n",
       " 'title': 'Machine Learning Roles and the Interview Process',\n",
       " 'section': 'A Brief History of Machine Learning and Data Science Job Titles',\n",
       " 'text': 'First, let’s walk through a brief history of job titles. I decided to start with this section to dispel some myths about the “data scientist” job title and shed some light on why there are so many ML-related job titles. After understanding this history, you should be more aware of what job titles to aim for yourself. If you’ve ever been confused about the litany of titles such as machine learning engineer (MLE), product data sci‐ entist, MLOps engineer, and more, this section is for you. ML techniques aren’t a new thing; in 1985, David Ackley, Geoffrey E. Hinton, and Terrence J. Sejnowski popularized the Boltzmann Machine algorithm. 3 Even before that, regression techniques 4 had early developments in the 1800s. There have long been jobs and roles that use modeling techniques to forecast and predict. Econome‐ tricians, statisticians, financial modelers, physics modelers, and biochemical modelers have existed as professions for decades. The main difference is that there were much smaller datasets compared to the modern day (barring simulations). It was only in recent years, just before the 21st century, when compute power started to increase exponentially. In addition, advances in distributed and parallel computing created a cycle in which “big data” became more readily available. This allowed practitioners to apply that advanced compute power to millions or billions of data points. Larger datasets started being accumulated and distributed for ML research, such as WordNet, 5 and, subsequently, ImageNet, 6 a project led by Fei-Fei Li. These collective efforts laid the foundation for even more ML breakthroughs. AlexNet 7 was released in 2012, achieving high accuracy in the ImageNet challenge, 8 which demonstrated that deep learning can be adept at humanlike tasks at a scale that had not been seen before. Many ML practitioners see this as a time when machine learning, deep learning, and related topics increased by leaps and bounds in terms of recognition from the broader population, not just the AI community. The recent popularity of generative AI (such as ChatGPT) in 2022 and 2023 didn’t come out of nowhere, nor did the deepfakes, self-driving cars, chess bots, and more that came before it; these applica‐ tions were the results of many advances over recent years. “Data scientist” as a job title began as an umbrella term, when the ML and data fields were less mature. The term “data scientist” on Google Trends , which measures the popularity of search terms, surged in 2012. That was the year when that article was published by Harvard Business Review: “Data Scientist: The Sexiest Job of the 21st Century.” 9 By April 2013, the search popularity of “data scientist” was already tied with “statistician” and subsequently surpassed it by magnitudes, as shown in Figure 1-2 . Back in those days, there wasn’t a narrow divide between infrastructure jobs and model training, though. For example, Kubernetes was first released in 2014, but companies have taken some time to adopt it for orchestrating ML jobs. So now there are more specific job titles for ML infrastructure that didn’t exist before. Figure 1-2. Search popularity for the terms “data scientist,” “machine learning engi‐ neer,” and “statistician” on Google Trends (retrieved August 9, 2023). As social media, web recommender systems, and other modern use cases increased, companies started gathering much more granular data, such as clickstream data , which is data collected as a user browses a website or app. Another recent advance‐ ment is an average corporation being able to store the sheer amount of telemetry from machines and Internet of Things (IoT) devices. Previously, data scientists may have worked with data that was updated weekly or daily. Now, as many applications update more frequently or in real time, more infrastructure is needed to serve ML functionality in web products and apps, so more jobs have been created around those functions as well. In short: as the machine learning lifecycle grew more complex, more job titles were created to describe the new skills that a full ML team now requires. I’ll elaborate more on the job titles and ML lifecycle later in this chapter. All of this happened within the last decade, and companies don’t always change their job titles to reflect how the roles have become more specialized. Regardless, as a can‐ didate, knowing this history can help reduce confusion and frustration from applying for a job and finding the role is different from another company’s job with the exact same title. See Table 1-1 for previous trends in ML-related job titles and Table 1-2 for current trends in ML job titles. Table 1-1. Previous trends of ML and data job titles Table 1-2. Current trends of ML and data job titles With that history to explain why you will encounter different job titles, I’ll elaborate on each of these job titles and their responsibilities.',\n",
       " 'id': '9a2356679c',\n",
       " 'text_vector': [0.06606891006231308,\n",
       "  0.04531856253743172,\n",
       "  -0.07584855705499649,\n",
       "  -0.015627508983016014,\n",
       "  -0.00380276283249259,\n",
       "  0.028007833287119865,\n",
       "  0.0754760354757309,\n",
       "  -0.018123220652341843,\n",
       "  0.008582300506532192,\n",
       "  0.030267365276813507,\n",
       "  0.053311970084905624,\n",
       "  0.04067913070321083,\n",
       "  -0.0052957115694880486,\n",
       "  0.03953951597213745,\n",
       "  0.03824090212583542,\n",
       "  -0.06374721229076385,\n",
       "  0.003309109713882208,\n",
       "  0.013971514068543911,\n",
       "  -0.0002465914294589311,\n",
       "  -0.010918994434177876,\n",
       "  -0.03460480645298958,\n",
       "  -0.007678858004510403,\n",
       "  0.009301344864070415,\n",
       "  0.07720332592725754,\n",
       "  -0.0413946695625782,\n",
       "  -0.0010991183808073401,\n",
       "  0.029970597475767136,\n",
       "  -0.013293800875544548,\n",
       "  0.0029220327269285917,\n",
       "  0.03814472630620003,\n",
       "  0.022476427257061005,\n",
       "  -0.042439717799425125,\n",
       "  0.021363502368330956,\n",
       "  0.03257731720805168,\n",
       "  2.079729256365681e-06,\n",
       "  -0.0034328100737184286,\n",
       "  0.027217580005526543,\n",
       "  0.044020239263772964,\n",
       "  -0.03004377707839012,\n",
       "  -0.09820341318845749,\n",
       "  0.03330150246620178,\n",
       "  -0.06206883490085602,\n",
       "  0.0117797227576375,\n",
       "  0.026507128030061722,\n",
       "  -0.018568409606814384,\n",
       "  0.007624240592122078,\n",
       "  0.1042281910777092,\n",
       "  -0.028022192418575287,\n",
       "  -0.025550968945026398,\n",
       "  -0.01998484879732132,\n",
       "  0.01871972344815731,\n",
       "  -0.06893045455217361,\n",
       "  0.05362166836857796,\n",
       "  -0.00026781688211485744,\n",
       "  0.0027046920731663704,\n",
       "  0.01537004392594099,\n",
       "  0.018221532925963402,\n",
       "  0.06257844716310501,\n",
       "  0.01126670092344284,\n",
       "  -0.0395016111433506,\n",
       "  -0.005242536310106516,\n",
       "  0.07580775022506714,\n",
       "  0.018005216494202614,\n",
       "  -0.0005650149541907012,\n",
       "  0.01900913193821907,\n",
       "  0.05989791080355644,\n",
       "  0.0017558903200551867,\n",
       "  -0.009293802082538605,\n",
       "  -0.021128876134753227,\n",
       "  -0.00982658937573433,\n",
       "  -0.003831487149000168,\n",
       "  -0.033346984535455704,\n",
       "  -0.025827178731560707,\n",
       "  -0.021122025325894356,\n",
       "  0.02961868979036808,\n",
       "  0.04232271760702133,\n",
       "  -0.03837832435965538,\n",
       "  -0.0046745711006224155,\n",
       "  0.007481447421014309,\n",
       "  -0.03835546225309372,\n",
       "  0.01964222826063633,\n",
       "  0.02881629578769207,\n",
       "  0.015349695459008217,\n",
       "  0.03103875368833542,\n",
       "  -0.03303079679608345,\n",
       "  0.047387149184942245,\n",
       "  -0.04087924212217331,\n",
       "  -0.023438507691025734,\n",
       "  0.07196937501430511,\n",
       "  0.02605152316391468,\n",
       "  0.049340229481458664,\n",
       "  -0.0011889338493347168,\n",
       "  0.028738314285874367,\n",
       "  0.009924503974616528,\n",
       "  -0.011536595411598682,\n",
       "  0.013317717239260674,\n",
       "  -0.0069163525477051735,\n",
       "  -0.030664220452308655,\n",
       "  -0.03107013739645481,\n",
       "  -0.03370391204953194,\n",
       "  0.0018016074318438768,\n",
       "  -0.014760669320821762,\n",
       "  0.040581174194812775,\n",
       "  0.011700952425599098,\n",
       "  -0.014479339122772217,\n",
       "  0.020870819687843323,\n",
       "  0.0002638025034684688,\n",
       "  -0.00817932840436697,\n",
       "  0.0025816624984145164,\n",
       "  -0.04894799739122391,\n",
       "  -0.04194409400224686,\n",
       "  -0.041730381548404694,\n",
       "  0.011076243594288826,\n",
       "  -0.031705331057310104,\n",
       "  0.01189903263002634,\n",
       "  0.027185821905732155,\n",
       "  0.00047855201410129666,\n",
       "  0.03057236783206463,\n",
       "  -0.03890026733279228,\n",
       "  -0.046381451189517975,\n",
       "  -0.05449884757399559,\n",
       "  0.04013647511601448,\n",
       "  0.032110102474689484,\n",
       "  0.053272999823093414,\n",
       "  -0.04501698911190033,\n",
       "  -0.04790934920310974,\n",
       "  -0.005251242779195309,\n",
       "  0.03849092498421669,\n",
       "  0.04074351117014885,\n",
       "  -0.006842250470072031,\n",
       "  0.024030065163969994,\n",
       "  -0.01352503802627325,\n",
       "  -0.0047929114662110806,\n",
       "  0.004801218397915363,\n",
       "  0.07695091515779495,\n",
       "  0.03469907492399216,\n",
       "  0.0024456805549561977,\n",
       "  0.04805701598525047,\n",
       "  -0.005186579190194607,\n",
       "  -0.033008210361003876,\n",
       "  -0.007145306095480919,\n",
       "  -0.03687674179673195,\n",
       "  0.0069240303710103035,\n",
       "  0.01807449385523796,\n",
       "  0.006329546682536602,\n",
       "  0.017354682087898254,\n",
       "  -0.04495503753423691,\n",
       "  -0.0035321894101798534,\n",
       "  -0.006921124178916216,\n",
       "  0.0018134437268599868,\n",
       "  -0.0738353282213211,\n",
       "  0.020462598651647568,\n",
       "  -0.029939092695713043,\n",
       "  -0.008973566815257072,\n",
       "  0.07127561420202255,\n",
       "  0.004359736107289791,\n",
       "  -0.014378378167748451,\n",
       "  0.027597876265645027,\n",
       "  0.03494704142212868,\n",
       "  0.02766389772295952,\n",
       "  -0.029038937762379646,\n",
       "  0.006079044658690691,\n",
       "  0.07711493968963623,\n",
       "  0.03673067316412926,\n",
       "  -0.013300592079758644,\n",
       "  -0.03998706117272377,\n",
       "  -0.027641819790005684,\n",
       "  0.005531721282750368,\n",
       "  -0.05451449751853943,\n",
       "  0.05231975018978119,\n",
       "  -0.017225516960024834,\n",
       "  -0.01773797534406185,\n",
       "  0.003748881397768855,\n",
       "  0.028564603999257088,\n",
       "  0.021129801869392395,\n",
       "  0.009148807264864445,\n",
       "  0.02449561096727848,\n",
       "  0.08051370084285736,\n",
       "  0.03769601136445999,\n",
       "  -0.008803902193903923,\n",
       "  0.02850445546209812,\n",
       "  -0.04532962664961815,\n",
       "  0.017087947577238083,\n",
       "  0.022892268374562263,\n",
       "  -0.045863185077905655,\n",
       "  -0.011087359860539436,\n",
       "  -0.07216333597898483,\n",
       "  -0.038531720638275146,\n",
       "  -0.013985269702970982,\n",
       "  -0.023124217987060547,\n",
       "  0.0766829401254654,\n",
       "  0.01453989278525114,\n",
       "  -0.019872210919857025,\n",
       "  0.020869798958301544,\n",
       "  0.03782374784350395,\n",
       "  -0.03671935945749283,\n",
       "  -0.050103649497032166,\n",
       "  -0.0010222081327810884,\n",
       "  -0.001558128627948463,\n",
       "  0.04118221625685692,\n",
       "  -0.05239838734269142,\n",
       "  -0.03697893023490906,\n",
       "  -0.06598374247550964,\n",
       "  0.029649225994944572,\n",
       "  0.034157101064920425,\n",
       "  -0.02445690892636776,\n",
       "  -0.06481662392616272,\n",
       "  -0.04938056319952011,\n",
       "  0.002515654545277357,\n",
       "  -0.01163905393332243,\n",
       "  -0.012934372760355473,\n",
       "  0.008459903299808502,\n",
       "  -0.050200898200273514,\n",
       "  0.03042571432888508,\n",
       "  -0.02022688090801239,\n",
       "  -0.005065116565674543,\n",
       "  0.006720611825585365,\n",
       "  -0.0393737368285656,\n",
       "  0.014697501435875893,\n",
       "  0.00017506499716546386,\n",
       "  -0.001132841338403523,\n",
       "  -0.002252863720059395,\n",
       "  -0.09398359805345535,\n",
       "  -0.016102958470582962,\n",
       "  -0.0696796178817749,\n",
       "  0.0237945057451725,\n",
       "  0.05232834443449974,\n",
       "  0.004358089063316584,\n",
       "  0.010724320076406002,\n",
       "  0.05368935316801071,\n",
       "  -0.002584524219855666,\n",
       "  -0.004418307915329933,\n",
       "  -0.006053366232663393,\n",
       "  -0.012549171224236488,\n",
       "  -0.01523069478571415,\n",
       "  -0.01238216832280159,\n",
       "  -0.011928270570933819,\n",
       "  0.03676788881421089,\n",
       "  -0.0376051664352417,\n",
       "  -0.009780357591807842,\n",
       "  -0.0011541753774508834,\n",
       "  0.03440144285559654,\n",
       "  -0.03515739366412163,\n",
       "  -0.017253302037715912,\n",
       "  0.002684232546016574,\n",
       "  -0.013121460564434528,\n",
       "  -0.008725123479962349,\n",
       "  0.012661011889576912,\n",
       "  -0.025318561121821404,\n",
       "  -0.057607922703027725,\n",
       "  0.05355115607380867,\n",
       "  -0.0400671549141407,\n",
       "  -0.028454983606934547,\n",
       "  0.03415612876415253,\n",
       "  -0.012389509938657284,\n",
       "  0.0042282165959477425,\n",
       "  0.007561819162219763,\n",
       "  -0.003925757948309183,\n",
       "  -0.011161931790411472,\n",
       "  -0.01257438212633133,\n",
       "  0.004901573061943054,\n",
       "  -0.010814359411597252,\n",
       "  0.017711933702230453,\n",
       "  0.020955758169293404,\n",
       "  -0.040588606148958206,\n",
       "  0.010667256079614162,\n",
       "  0.01803452894091606,\n",
       "  0.0024050564970821142,\n",
       "  -0.03758038580417633,\n",
       "  0.00028565613320097327,\n",
       "  0.003009356325492263,\n",
       "  0.0007151829195208848,\n",
       "  -0.04722214862704277,\n",
       "  -0.027198662981390953,\n",
       "  0.0008122437866404653,\n",
       "  0.008109611459076405,\n",
       "  0.022873103618621826,\n",
       "  -0.0020602906588464975,\n",
       "  -0.040730416774749756,\n",
       "  0.04841279610991478,\n",
       "  0.019382940605282784,\n",
       "  -0.04489132761955261,\n",
       "  -0.004527580924332142,\n",
       "  -0.04680744186043739,\n",
       "  -0.03085365891456604,\n",
       "  0.031186342239379883,\n",
       "  0.0713123083114624,\n",
       "  -0.01749725081026554,\n",
       "  0.01957760937511921,\n",
       "  -0.03963230550289154,\n",
       "  -0.036592934280633926,\n",
       "  0.01598355919122696,\n",
       "  -0.030292702838778496,\n",
       "  0.024436619132757187,\n",
       "  0.0023214814718812704,\n",
       "  0.02914116345345974,\n",
       "  -0.007625013589859009,\n",
       "  0.012297776527702808,\n",
       "  -0.009883164428174496,\n",
       "  0.022692741826176643,\n",
       "  -0.03238226845860481,\n",
       "  0.010917801409959793,\n",
       "  0.0478123240172863,\n",
       "  0.042903609573841095,\n",
       "  -0.024091273546218872,\n",
       "  -0.002253559185191989,\n",
       "  0.03988434374332428,\n",
       "  0.045700594782829285,\n",
       "  -0.021282298490405083,\n",
       "  -0.05791624262928963,\n",
       "  -0.005728038959205151,\n",
       "  -0.03647732362151146,\n",
       "  0.04149213060736656,\n",
       "  0.10073183476924896,\n",
       "  0.020527750253677368,\n",
       "  -0.08045247197151184,\n",
       "  -0.04772065579891205,\n",
       "  0.01932142861187458,\n",
       "  -0.007101878989487886,\n",
       "  0.030127782374620438,\n",
       "  -0.024174990132451057,\n",
       "  -0.039210692048072815,\n",
       "  0.0008273554849438369,\n",
       "  0.027834270149469376,\n",
       "  0.00034315374796278775,\n",
       "  -0.024012722074985504,\n",
       "  -0.09624817967414856,\n",
       "  0.0013241141568869352,\n",
       "  0.03476903960108757,\n",
       "  -0.013779825530946255,\n",
       "  0.010820349678397179,\n",
       "  -0.0029222164303064346,\n",
       "  -0.012951036915183067,\n",
       "  -0.01282590813934803,\n",
       "  0.01177946850657463,\n",
       "  -0.05410123988986015,\n",
       "  -0.00535534368827939,\n",
       "  -0.01906205341219902,\n",
       "  -0.02466508187353611,\n",
       "  -0.004356122575700283,\n",
       "  0.006209157407283783,\n",
       "  0.017151547595858574,\n",
       "  -0.01954115554690361,\n",
       "  -0.05501613765954971,\n",
       "  -0.033230748027563095,\n",
       "  0.006833230145275593,\n",
       "  0.007417644374072552,\n",
       "  -0.01304837130010128,\n",
       "  -0.04773737117648125,\n",
       "  0.004429795779287815,\n",
       "  0.06166398525238037,\n",
       "  -0.00835472159087658,\n",
       "  0.005322097800672054,\n",
       "  -0.008785232901573181,\n",
       "  -0.00791714433580637,\n",
       "  -0.05100962147116661,\n",
       "  0.025196321308612823,\n",
       "  0.03646881878376007,\n",
       "  0.031153438612818718,\n",
       "  0.03680706024169922,\n",
       "  0.017008377239108086,\n",
       "  -0.049645163118839264,\n",
       "  -0.026324093341827393,\n",
       "  -0.02027708850800991,\n",
       "  -0.10212179273366928,\n",
       "  0.00787843856960535,\n",
       "  0.0002377682103542611,\n",
       "  -0.023459874093532562,\n",
       "  0.005685360170900822,\n",
       "  0.019479062408208847,\n",
       "  -0.03959747031331062,\n",
       "  -0.05073043331503868,\n",
       "  0.060207799077034,\n",
       "  0.04221693053841591,\n",
       "  -0.04446297138929367,\n",
       "  0.0145115302875638,\n",
       "  -0.01644154079258442,\n",
       "  0.04055437818169594,\n",
       "  -0.0269129890948534,\n",
       "  0.012730925343930721,\n",
       "  0.04868648573756218,\n",
       "  -0.05640551447868347,\n",
       "  0.008165411651134491,\n",
       "  0.023618215695023537,\n",
       "  0.010857492685317993,\n",
       "  -0.06186135858297348,\n",
       "  -0.05651771277189255,\n",
       "  -0.028259294107556343,\n",
       "  -0.008443672209978104,\n",
       "  0.05899100378155708,\n",
       "  -0.028514690697193146,\n",
       "  -0.0429510734975338,\n",
       "  -0.015106553211808205,\n",
       "  -0.039634548127651215,\n",
       "  -0.01071388553828001,\n",
       "  -0.007325134705752134,\n",
       "  0.02280302532017231,\n",
       "  -0.005779926665127277,\n",
       "  0.04193408042192459,\n",
       "  -0.007463559973984957,\n",
       "  0.0552663579583168,\n",
       "  -0.052493467926979065,\n",
       "  -0.005243164021521807,\n",
       "  0.020683612674474716,\n",
       "  -0.04542155563831329,\n",
       "  0.008331715129315853,\n",
       "  0.09297247231006622,\n",
       "  0.04360513389110565,\n",
       "  -0.09098030626773834,\n",
       "  0.09756780415773392,\n",
       "  -0.02945149689912796,\n",
       "  0.08422981202602386,\n",
       "  0.05244465172290802,\n",
       "  0.031239798292517662,\n",
       "  0.06164417788386345,\n",
       "  -0.015262868255376816,\n",
       "  -0.04119983687996864,\n",
       "  -0.04646046832203865,\n",
       "  0.022454669699072838,\n",
       "  -0.012235848233103752,\n",
       "  0.07515323907136917,\n",
       "  0.03544388711452484,\n",
       "  0.036679137498140335,\n",
       "  -0.03558730334043503,\n",
       "  -0.03826139122247696,\n",
       "  -0.054116927087306976,\n",
       "  -0.006655484903603792,\n",
       "  0.012116723693907261,\n",
       "  0.019443180412054062,\n",
       "  -0.043282344937324524,\n",
       "  -0.030636893585324287,\n",
       "  -0.019596515223383904,\n",
       "  -0.007878200151026249,\n",
       "  0.03868275508284569,\n",
       "  0.04207286611199379,\n",
       "  -0.007899442687630653,\n",
       "  -0.003663739887997508,\n",
       "  -0.04174764081835747,\n",
       "  -0.05212956294417381,\n",
       "  0.0777641162276268,\n",
       "  -0.016771579161286354,\n",
       "  0.06696739792823792,\n",
       "  -0.013741860166192055,\n",
       "  0.03219130262732506,\n",
       "  -0.03206454962491989,\n",
       "  0.04737213999032974,\n",
       "  -0.029888931661844254,\n",
       "  -0.08089249581098557,\n",
       "  -0.033023182302713394,\n",
       "  0.014175611548125744,\n",
       "  0.054730355739593506,\n",
       "  0.019531190395355225,\n",
       "  -0.012452976778149605,\n",
       "  0.07712072879076004,\n",
       "  -0.04848906770348549,\n",
       "  -0.02792203240096569,\n",
       "  -0.05703088268637657,\n",
       "  -0.020144730806350708,\n",
       "  -0.008493867702782154,\n",
       "  -0.022559810429811478,\n",
       "  0.04497664421796799,\n",
       "  0.008116108365356922,\n",
       "  -0.028598355129361153,\n",
       "  0.020461125299334526,\n",
       "  -0.062424518167972565,\n",
       "  0.046411123126745224,\n",
       "  0.11154387891292572,\n",
       "  0.0010989821748808026,\n",
       "  -0.00826630275696516,\n",
       "  -0.007976618595421314,\n",
       "  0.0016863218042999506,\n",
       "  -0.02629786916077137,\n",
       "  -0.026995521038770676,\n",
       "  0.014994101598858833,\n",
       "  0.03660009801387787,\n",
       "  0.013781029731035233,\n",
       "  -0.025223184376955032,\n",
       "  -0.009965931996703148,\n",
       "  0.00458912318572402,\n",
       "  -0.03425789624452591,\n",
       "  -0.0008328360272571445,\n",
       "  0.060735978186130524,\n",
       "  -0.03258571773767471,\n",
       "  -0.03275550901889801,\n",
       "  0.002879028907045722,\n",
       "  -0.027904454618692398,\n",
       "  0.03861277550458908,\n",
       "  0.007317420560866594,\n",
       "  -0.02847658284008503,\n",
       "  -0.054346490651369095,\n",
       "  0.05064050108194351,\n",
       "  0.05081033334136009,\n",
       "  0.015568842180073261,\n",
       "  -0.043860748410224915,\n",
       "  0.06052583083510399,\n",
       "  -0.06325481832027435,\n",
       "  -0.059563327580690384,\n",
       "  0.029067600145936012,\n",
       "  -0.027052899822592735,\n",
       "  0.050313252955675125,\n",
       "  0.018823884427547455,\n",
       "  0.007639425341039896,\n",
       "  -0.012172972783446312,\n",
       "  -0.03006257303059101,\n",
       "  0.04391228035092354,\n",
       "  -0.03157825395464897,\n",
       "  0.039480943232774734,\n",
       "  0.004037121776491404,\n",
       "  0.0026923182886093855,\n",
       "  0.0418529212474823,\n",
       "  -0.03694061562418938,\n",
       "  0.002784724347293377,\n",
       "  -0.061942461878061295,\n",
       "  -0.05743245780467987,\n",
       "  0.015872392803430557,\n",
       "  0.010635687969624996,\n",
       "  0.03938867151737213,\n",
       "  -0.008741693571209908,\n",
       "  -0.031767409294843674,\n",
       "  -0.010295013897120953,\n",
       "  0.002296960912644863,\n",
       "  -0.0021257305052131414,\n",
       "  -0.03231678530573845,\n",
       "  -0.00729492399841547,\n",
       "  0.03506103903055191,\n",
       "  -0.0038116180803626776,\n",
       "  -0.0356922447681427,\n",
       "  -0.03699394688010216,\n",
       "  -0.01977047324180603,\n",
       "  0.003479261649772525,\n",
       "  0.03993493691086769,\n",
       "  0.034821610897779465,\n",
       "  0.01446866150945425,\n",
       "  -0.0465506985783577,\n",
       "  0.03628890588879585,\n",
       "  -0.01677398383617401,\n",
       "  0.03791150450706482,\n",
       "  -0.012815563939511776,\n",
       "  0.05356059595942497,\n",
       "  -0.007672739215195179,\n",
       "  -0.004740254953503609,\n",
       "  0.01181875728070736,\n",
       "  0.0102028027176857,\n",
       "  -0.017471682280302048,\n",
       "  -0.02144976705312729,\n",
       "  -0.07845401763916016,\n",
       "  -0.013074511662125587,\n",
       "  0.04433221369981766,\n",
       "  0.012511640787124634,\n",
       "  0.03956323489546776,\n",
       "  0.005207272246479988,\n",
       "  0.022034581750631332,\n",
       "  -0.01341076847165823,\n",
       "  0.017888829112052917,\n",
       "  0.010471689514815807,\n",
       "  -5.4023564066342544e-33,\n",
       "  0.06273004412651062,\n",
       "  -0.03525228425860405,\n",
       "  0.07765353471040726,\n",
       "  0.061391446739435196,\n",
       "  -0.02384204789996147,\n",
       "  0.014497761614620686,\n",
       "  -0.0176616869866848,\n",
       "  0.028972890228033066,\n",
       "  -0.0482834130525589,\n",
       "  0.009528030641376972,\n",
       "  -0.03902558982372284,\n",
       "  -0.0032943724654614925,\n",
       "  0.005756794940680265,\n",
       "  0.015592397190630436,\n",
       "  0.04055174067616463,\n",
       "  -0.021079260855913162,\n",
       "  0.011296295560896397,\n",
       "  0.0051696146838366985,\n",
       "  0.06545768678188324,\n",
       "  0.023220039904117584,\n",
       "  -0.07087520509958267,\n",
       "  0.01078211423009634,\n",
       "  -0.012268850579857826,\n",
       "  -0.04977979511022568,\n",
       "  0.006346903275698423,\n",
       "  0.024544019252061844,\n",
       "  0.02209760993719101,\n",
       "  -0.03226298838853836,\n",
       "  -0.007752036675810814,\n",
       "  -0.005610586144030094,\n",
       "  0.038247209042310715,\n",
       "  0.07052814215421677,\n",
       "  -0.004235969390720129,\n",
       "  -0.06332997977733612,\n",
       "  -0.06598049402236938,\n",
       "  0.036838412284851074,\n",
       "  -0.050730396062135696,\n",
       "  0.052630193531513214,\n",
       "  -0.02322184108197689,\n",
       "  -0.022501178085803986,\n",
       "  0.018955077975988388,\n",
       "  0.019748743623495102,\n",
       "  0.06697692722082138,\n",
       "  0.04411890730261803,\n",
       "  -0.0765247792005539,\n",
       "  0.0074395383708179,\n",
       "  0.024983147159218788,\n",
       "  -0.02730625681579113,\n",
       "  0.02067146636545658,\n",
       "  -0.04548447206616402,\n",
       "  0.02184279076755047,\n",
       "  0.00266981590539217,\n",
       "  -0.051851674914360046,\n",
       "  0.04077094420790672,\n",
       "  0.03492320701479912,\n",
       "  0.02548070438206196,\n",
       "  -0.017479341477155685,\n",
       "  0.021920453757047653,\n",
       "  -0.06614820659160614,\n",
       "  0.0018970170058310032,\n",
       "  0.04006213694810867,\n",
       "  -0.04857800155878067,\n",
       "  0.07349228858947754,\n",
       "  0.06810744106769562,\n",
       "  0.041173502802848816,\n",
       "  0.04260774701833725,\n",
       "  0.13043127954006195,\n",
       "  0.02215079963207245,\n",
       "  -0.01227223314344883,\n",
       "  0.06180323660373688,\n",
       "  0.02483632043004036,\n",
       "  0.06593676656484604,\n",
       "  0.0071989563293755054,\n",
       "  0.010368443094193935,\n",
       "  0.013322046957910061,\n",
       "  -0.0590553879737854,\n",
       "  -0.03556472063064575,\n",
       "  -0.021196307614445686,\n",
       "  -0.00106766726821661,\n",
       "  -0.06417965888977051,\n",
       "  0.010434252209961414,\n",
       "  0.004031035583466291,\n",
       "  -0.008688749745488167,\n",
       "  -0.08099931478500366,\n",
       "  0.004019645042717457,\n",
       "  -0.0077246930450201035,\n",
       "  0.028778111562132835,\n",
       "  0.025643453001976013,\n",
       "  -0.02500726282596588,\n",
       "  -0.04285277798771858,\n",
       "  0.0018891413928940892,\n",
       "  0.1072169840335846,\n",
       "  0.003145250491797924,\n",
       "  -0.07025501877069473,\n",
       "  0.006670638918876648,\n",
       "  -0.013953391462564468,\n",
       "  -0.021985316649079323,\n",
       "  0.037968479096889496,\n",
       "  0.04393798112869263,\n",
       "  0.020094111561775208,\n",
       "  -0.09405159950256348,\n",
       "  -0.025714024901390076,\n",
       "  -0.07681666314601898,\n",
       "  0.033112142235040665,\n",
       "  0.022592831403017044,\n",
       "  0.03209444135427475,\n",
       "  -0.01951802708208561,\n",
       "  0.01557836215943098,\n",
       "  0.001193723175674677,\n",
       "  -0.022580455988645554,\n",
       "  0.006208548787981272,\n",
       "  0.026494471356272697,\n",
       "  0.010143030434846878,\n",
       "  -0.012842662632465363,\n",
       "  -0.005834595300257206,\n",
       "  -0.028992321342229843,\n",
       "  0.024958712980151176,\n",
       "  -0.024606449529528618,\n",
       "  -0.007937591522932053,\n",
       "  -0.014013553969562054,\n",
       "  0.031215166673064232,\n",
       "  -0.02569190226495266,\n",
       "  -0.014582696370780468,\n",
       "  -0.029290003702044487,\n",
       "  0.003837253199890256,\n",
       "  -0.04034789651632309,\n",
       "  -0.013712234795093536,\n",
       "  -0.045362070202827454,\n",
       "  0.03771521523594856,\n",
       "  -0.046821728348731995,\n",
       "  -0.029563140124082565,\n",
       "  -0.024172931909561157,\n",
       "  2.674981942618615e-07,\n",
       "  0.00598176522180438,\n",
       "  0.05083223059773445,\n",
       "  0.007102744188159704,\n",
       "  0.028811227530241013,\n",
       "  0.01831391453742981,\n",
       "  0.016095614060759544,\n",
       "  0.025160428136587143,\n",
       "  -0.02432354725897312,\n",
       "  0.004398027900606394,\n",
       "  0.030485166236758232,\n",
       "  0.02945248782634735,\n",
       "  -0.011351828463375568,\n",
       "  0.000556918210349977,\n",
       "  -0.06351268291473389,\n",
       "  -0.027407990768551826,\n",
       "  -0.09931714832782745,\n",
       "  -0.028732728213071823,\n",
       "  -0.030628109350800514,\n",
       "  -0.06863461434841156,\n",
       "  0.0421827994287014,\n",
       "  0.025273695588111877,\n",
       "  0.018677765503525734,\n",
       "  0.035644251853227615,\n",
       "  -0.03694610297679901,\n",
       "  0.01975378952920437,\n",
       "  -0.039749741554260254,\n",
       "  -0.01602136343717575,\n",
       "  -0.02045288495719433,\n",
       "  0.07754141837358475,\n",
       "  0.03762979060411453,\n",
       "  0.0281163789331913,\n",
       "  0.06645344942808151,\n",
       "  0.021740468218922615,\n",
       "  0.023830760270357132,\n",
       "  0.020803887397050858,\n",
       "  -0.00778147904202342,\n",
       "  0.01782580278813839,\n",
       "  0.00946755614131689,\n",
       "  0.02644900418817997,\n",
       "  0.04422738403081894,\n",
       "  0.025743382051587105,\n",
       "  0.017160259187221527,\n",
       "  0.01792924292385578,\n",
       "  -0.026933642104268074,\n",
       "  0.026158511638641357,\n",
       "  -0.021689968183636665,\n",
       "  -0.08127816766500473,\n",
       "  -0.035310667008161545,\n",
       "  -0.012588229030370712,\n",
       "  -0.013935275375843048,\n",
       "  -0.0015044432366266847,\n",
       "  -0.040959812700748444,\n",
       "  0.028187310323119164,\n",
       "  -0.04556509107351303,\n",
       "  -0.002020201412960887,\n",
       "  -0.024906707927584648,\n",
       "  -0.0238063745200634,\n",
       "  0.02405397593975067,\n",
       "  0.02506897784769535,\n",
       "  0.0264270082116127,\n",
       "  -0.03306831046938896,\n",
       "  -0.03008778765797615,\n",
       "  0.02162666618824005,\n",
       "  -0.01203906536102295,\n",
       "  0.07563776522874832,\n",
       "  0.009789579547941685,\n",
       "  0.018244445323944092,\n",
       "  2.2403955758075737e-34,\n",
       "  0.0027073740493506193,\n",
       "  0.03626491501927376,\n",
       "  -0.010984865948557854,\n",
       "  -0.015721598640084267,\n",
       "  -0.004851104225963354,\n",
       "  0.007580568082630634,\n",
       "  -0.012230148538947105,\n",
       "  -0.00745063740760088,\n",
       "  -0.013364853337407112,\n",
       "  0.0005683943745680153,\n",
       "  -0.06282488256692886]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operations[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add documents to the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in operations:\n",
    "    try:\n",
    "        es_client.index(index=index_name, body=doc)\n",
    "    except Exception as e:\n",
    "        print(f\"Error when indexing the document: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(vector_search_term):\n",
    "    semantic_query = {\n",
    "    \"size\": 15,\n",
    "    \"knn\": {\n",
    "        \"field\": \"text_vector\",\n",
    "        \"query_vector\": vector_search_term,\n",
    "        \"k\": 4,  \n",
    "        \"num_candidates\": 10000  \n",
    "    },\n",
    "    \"_source\": [\"id\", \"text\", \"section\", \"title\"] \n",
    "    }\n",
    "\n",
    "    semantic_results = execute_search(semantic_query)\n",
    "    return semantic_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nSemantic Search Results:\")\n",
    "# print(semantic_search(vector_search_term)['hits']['hits'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Search\n",
    "\n",
    "Combination of both full-text and vector search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_search(search_term, vector_search_term):\n",
    "    hybrid_query = {\n",
    "        \"size\": 15,\n",
    "        \"query\": {\n",
    "            \"multi_match\": {\n",
    "                \"query\": search_term,\n",
    "                \"fields\": [\"text^3\", \"section\", \"title\"],\n",
    "                \"type\": \"best_fields\"\n",
    "            }\n",
    "        },\n",
    "        \"knn\": {\n",
    "            \"field\": \"text_vector\",\n",
    "            \"query_vector\": vector_search_term,\n",
    "            \"k\": 4,\n",
    "            \"num_candidates\": 10000\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Ejecuta la búsqueda híbrida usando la consulta modificada\n",
    "    hybrid_results = execute_search(hybrid_query)\n",
    "    return hybrid_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Text-Vector Search Results:\")\n",
    "# print(hybrid_search(search_term, vector_search_term)['hits']['hits'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df = pd.read_csv('../../data/ground_truth_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth =  gt_df.to_dict(orient ='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation full-text search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2969b88076b42c188fb9facef22a0c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "relevance_total = []\n",
    "\n",
    "for q in tqdm(ground_truth):\n",
    "    doc_id = q['text_id']\n",
    "    text_results = full_text_search(q['question'])\n",
    "    hits = text_results.get('hits', {}).get('hits', [])\n",
    "    relevance = [doc['_source']['id'] == doc_id for doc in hits]\n",
    "    relevance_total.append(relevance)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6625, 0.9441591741591752)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_rate(relevance_total), mrr(relevance_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalutation Sematinc search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "574ac735b1a8452a8bbac6f104c48f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "relevance_total = []\n",
    "\n",
    "for q in tqdm(ground_truth):\n",
    "    doc_id = q['text_id']\n",
    "    vector = model.encode(q[\"question\"]).tolist()\n",
    "    text_results = semantic_search(vector)\n",
    "    hits = text_results.get('hits', {}).get('hits', [])\n",
    "    relevance = [doc['_source']['id'] == doc_id for doc in hits]\n",
    "    relevance_total.append(relevance)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3958333333333333, 0.509722222222222)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_rate(relevance_total), mrr(relevance_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba95a48f54d248e4b0ba1daaa67cf3ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "relevance_total = []\n",
    "\n",
    "for q in tqdm(ground_truth):\n",
    "    doc_id = q['text_id']\n",
    "    vector = model.encode(q[\"question\"]).tolist()\n",
    "    text_results = hybrid_search(search_term, vector)\n",
    "    hits = text_results.get('hits', {}).get('hits', [])\n",
    "    relevance = [doc['_source']['id'] == doc_id for doc in hits]\n",
    "    relevance_total.append(relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.10416666666666667, 0.06854816479816478)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_rate(relevance_total), mrr(relevance_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "\n",
    "The best search type is full-text search within elasticsearch.\n",
    "\n",
    "Observations: \n",
    "\n",
    "We have to take into consideration that this book is technical yet very general so some keywords could be found in several parts of the book. \n",
    "\n",
    "When applying retrieval evaluation we use the ground truth data created by llama2 (5 questions per section) but the content of our book is very heterogeneus i.e. some sections are very generalistic, others mostly introductory, some are also very short or with a lot of diagrams... this can lead in our case to worse evaluation performance. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interview_preparation_bot-ZQDkHgpI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
