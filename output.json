[
  {
    "chapter": "CHAPTER 1",
    "title": "Machine Learning Roles and the Interview Process",
    "content": [
      {
        "text": "In the first part of this chapter, I’ll walk through the structure of this book. Then, I’ll discuss the various job titles and roles that use ML skills in industry. I’ll also clarify the responsibilities of various job titles, such as data scientist, machine learning engineer, and so on, as this is a common point of confusion for job seekers. These will be illustrated with an ML skills matrix and ML lifecycle that will be referenced throughout the book. The second part of this chapter walks through the interview process, from beginning to end. I’ve mentored candidates who appreciated this overview since online resources often focus on specific pieces of the interview but not how they all connect together and result in an offer. Especially for new graduates and readers coming from different industries, this chapter helps get everyone on the same page as well as clarifies the process. The interconnecting pieces of interviews are complex, with many types of combina‐ tions depending on the ML role you’re aiming for. This overview will help set the stage, so you’ll know what to focus your time on. For example, some online resources focus on knowledge specific to “product data scientists,” but will title the course or article “data scientist interview tips” without differentiating. For a newcomer, it’s hard to tell if that is relevant to your own career interests. After this chapter, you’ll be able to tell what skills are required for each job title, and in Chapter 2 , you’ll be able to parse out that information yourself from job postings and make your resume as relevant to the job title and job posting as possible."
      },
      {
        "section": "Overview of This Book"
      },
      {
        "text": "This chapter focuses on helping you differentiate among various ML roles, and walks through the entire interview process, as illustrated in Figure 1-1 : • Job applications and resume ( Chapter 2 ) • Technical interviews — Machine learning (Chapters 3 , 4 , and 6 ) — Coding/programming ( Chapter 5 ) • Behavioral interviews ( Chapter 7 ) • Your interview roadmap ( Chapter 8 ) • Post-interview and follow-up ( Chapter 9 ) Figure 1-1. Overview of the chapters and how they tie into the ML interview process. Depending on where you are in your ML interview journey, I encourage you to focus on the chapters and sections that seem relevant to you. I’ve also planned the book to be referenced as you go along; for example, you might iterate on your resume multi‐ ple times and then flip back to Chapter 2 when needed. The same applies to the other chapters. With that overview, let’s continue. The companion site to this book, https://susanshu.substack.com , features bonus content, helper resources, and more."
      },
      {
        "section": "A Brief History of Machine Learning and Data Science Job Titles"
      },
      {
        "text": "First, let’s walk through a brief history of job titles. I decided to start with this section to dispel some myths about the “data scientist” job title and shed some light on why there are so many ML-related job titles. After understanding this history, you should be more aware of what job titles to aim for yourself. If you’ve ever been confused about the litany of titles such as machine learning engineer (MLE), product data sci‐ entist, MLOps engineer, and more, this section is for you. ML techniques aren’t a new thing; in 1985, David Ackley, Geoffrey E. Hinton, and Terrence J. Sejnowski popularized the Boltzmann Machine algorithm. Even before that, regression techniques had early developments in the 1800s. There have long been jobs and roles that use modeling techniques to forecast and predict. Econome‐ tricians, statisticians, financial modelers, physics modelers, and biochemical modelers have existed as professions for decades. The main difference is that there were much smaller datasets compared to the modern day (barring simulations). It was only in recent years, just before the 21st century, when compute power started to increase exponentially. In addition, advances in distributed and parallel computing created a cycle in which “big data” became more readily available. This allowed practitioners to apply that advanced compute power to millions or billions of data points. Larger datasets started being accumulated and distributed for ML research, such as WordNet, and, subsequently, ImageNet, a project led by Fei-Fei Li. These collective efforts laid the foundation for even more ML breakthroughs. AlexNet was released in 2012, achieving high accuracy in the ImageNet challenge, which demonstrated that deep learning can be adept at humanlike tasks at a scale that had not been seen before. Many ML practitioners see this as a time when machine learning, deep learning, and related topics increased by leaps and bounds in terms of recognition from the broader population, not just the AI community. The recent popularity of generative AI (such as ChatGPT) in 2022 and 2023 didn’t come out of nowhere, nor did the deepfakes, self-driving cars, chess bots, and more that came before it; these applica‐ tions were the results of many advances over recent years. “Data scientist” as a job title began as an umbrella term, when the ML and data fields were less mature. The term “data scientist” on Google Trends , which measures the popularity of search terms, surged in 2012. That was the year when that article was published by Harvard Business Review: “Data Scientist: The Sexiest Job of the 21st Century.” By April 2013, the search popularity of “data scientist” was already tied with “statistician” and subsequently surpassed it by magnitudes, as shown in Figure 1-2 . Back in those days, there wasn’t a narrow divide between infrastructure jobs and model training, though. For example, Kubernetes was first released in 2014, but companies have taken some time to adopt it for orchestrating ML jobs. So now there are more specific job titles for ML infrastructure that didn’t exist before. Figure 1-2. Search popularity for the terms “data scientist,” “machine learning engi‐ neer,” and “statistician” on Google Trends (retrieved August 9, 2023). As social media, web recommender systems, and other modern use cases increased, companies started gathering much more granular data, such as clickstream data , which is data collected as a user browses a website or app. Another recent advance‐ ment is an average corporation being able to store the sheer amount of telemetry from machines and Internet of Things (IoT) devices. Previously, data scientists may have worked with data that was updated weekly or daily. Now, as many applications update more frequently or in real time, more infrastructure is needed to serve ML functionality in web products and apps, so more jobs have been created around those functions as well. In short: as the machine learning lifecycle grew more complex, more job titles were created to describe the new skills that a full ML team now requires. I’ll elaborate more on the job titles and ML lifecycle later in this chapter. All of this happened within the last decade, and companies don’t always change their job titles to reflect how the roles have become more specialized. Regardless, as a can‐ didate, knowing this history can help reduce confusion and frustration from applying for a job and finding the role is different from another company’s job with the exact same title. See Table 1-1 for previous trends in ML-related job titles and Table 1-2 for current trends in ML job titles. Table 1-1. Previous trends of ML and data job titles Table 1-2. Current trends of ML and data job titles With that history to explain why you will encounter different job titles, I’ll elaborate on each of these job titles and their responsibilities."
      },
      {
        "section": "Job Titles Requiring ML Experience"
      },
      {
        "text": "Here is a nonexhaustive list of job titles for ML (or closely related) roles: • Data scientist • Machine learning engineer • Applied scientist • Software engineer, machine learning • MLOps engineer • Product data scientist • Data analyst • Decision scientist • Data engineer • Research scientist • Research engineer As I discussed “A Brief History of Machine Learning and Data Science Job Titles” on page 3 , each role is responsible for a different part of the ML lifecycle. A job title alone does not convey what the job entails. As a job seeker, be warned: in different companies, completely different titles might end up doing similar jobs! As illustrated in Figure 1-3 , your ML job title will depend on the company, the team, and which part(s) of the ML lifecycle your role is responsible for. To give specific examples of how job titles can depend on the company or organiza‐ tion that is hiring for the job—based on real people I’ve spoken to, job descriptions, and job interviews—the person responsible for training ML models but not for build‐ ing the underlying platform might be called the following: • Software engineer (ML) or data scientist (Google) • Applied scientist (Amazon) • Machine learning engineer (Meta, Pinterest) • Data scientist (Elastic, the team where I work) • Data scientist (Unity) Figure 1-3. What’s in a machine learning job title? By the time this book is published, any of the job titles within these companies and teams may have changed. Regardless, it demon‐ strates the point that ML titles may vary between companies and even between different teams in the same company. The job title also depends on the organization, the department, and so on. Some departments in Google have the data scientist job title, and some don’t. At the com‐ panies where I’ve worked, my teams had data scientists train ML models while MLEs built the infrastructure (working all day in tools such as Kubernetes, Terraform, Jen‐ kins, and so on). In some other companies, MLEs are the ones who train ML models. As a personal example, my work experience has heavily involved ML model training, so I apply for jobs that have the title “machine learning engineer” or “data scientist.” I’ll provide more examples of skills and roles that could be a good fit for your inter‐ ests and skills in the following sections. As mentioned in the Preface , this book focuses more on the industry applications of ML rather than research roles. Here’s a brief overview of research roles: Requirements Most often PhD. Responsibilities Similar to academic roles/academia, such as conducting research and coming up with novel algorithms and improvements, authoring papers, presenting at aca‐ demic conferences, and so on. If you’re in a research role in industry , such as a researcher at Google DeepMind, the main difference is that there isn’t a require‐ ment for teaching (that I know of)."
      },
      {
        "section": "Machine Learning Lifecycle"
      },
      {
        "text": "In industry, it is an expectation for applied ML projects to eventually improve the customer experience—for example, a better recommender system that shows the user more relevant videos, news, and social media posts. In industry, “customer” can also mean internal customers: people within the same company or organization. For example, your team builds ML models that predict demand, which helps your com‐ pany’s logistics department better plan its shipment schedules. Regardless of whether the user is external or internal, many components are involved in building a full- fledged, end-to-end ML product. I’ll walk through a simplified example. First, there needs to be data, as most ML is trained and tested with large amounts of data. Someone needs to make sure the raw data is brought in (ingested) so that it’s easily accessible later on for data analysis, ML, reporting and monitoring, and so on. This is illustrated by step A (data) in Figure 1-4 . Next, with the data in place, someone with knowledge of ML algorithms and tools will use the data to start ML development. This is illustrated by step B (machine learning development) in Figure 1-4 . This involves feature engineering, model train‐ ing, and evaluation. If the results aren’t great, there is a lot of iteration in step B, and this person might enhance their feature engineering or model training, or even go back to step A and request that more data be ingested. Once there are somewhat satisfactory results, they’ll move on to step C (machine learning deployment), which connects the ML models to customers. Depending on the type of ML project, it could be deployed to a website, app, internal dashboard, and so on. Of course, they’d like to make sure the ML is working properly, so any good team will have a way to monitor the results. In ML there are two main types of potential issues. The first is that something in the software layer doesn’t work, such as bugs in the code. The second is a data or ML model issue—for example, in the model-development phase, the model outputs normal results, but after deployment/ release, there is data imbalance, so then the model results become undesirable. From step C onward, there can be more iteration back to step B to improve the models and run more experiments in step C again. Figure 1-4. Machine learning lifecycle (the graph is simplified for understanding). In the machine learning lifecycle I just walked through, a lot of skills are required. Data pipelines, model training, maintaining continuous integration and continuous deployment (CI/CD): as a job candidate, what should you be learning to prepare for the interview? Thankfully, as I mentioned in “A Brief History of Machine Learning and Data Science Job Titles” on page 3 companies nowadays might hire people who have a subset of these skills. For example, they need some people specialized in step A (data engineering), some specialized in step B (ML development), some in step C (ML deployment), and so forth. I emphasize the might since it still differs depending on the company or team; I will walk through some scenarios. Startup roles will usually wear more hats, meaning they will need to do the jobs in multiple steps in the machine learning lifecycle as illustrated in Figure 1-4 . Here’s an example: Usually, startup companies have the goal of shipping an end-to-end product, but because they have fewer customers they might care less about the scale and stability (at an early stage). Hence, it’s more likely that the person developing and training ML models is the same person doing data analysis and presenting to stakeholders, or even the same person building the platform infrastructure. An ML team in a startup might simply have fewer people. For example, the startup might have 30 software engineers and data people in total, whereas larger corporations could have a team of data ana‐ lysts alone numbering 30 people to disperse the workload. If the company and/or team has grown enough, it is more likely the ML roles have become more specialized. Generally, the larger the team, the more specialized the role. If the “machine learning engineer” at a larger company trains models, then it’s likely they don’t wear two or three hats at once, as they might at a startup. Instead, the big company hires more people to fill those roles. That isn’t to say the work is simpler at a larger company. In fact, there’s often more data, more scale, and more downsides if the ML functionality goes down, so each MLE’s time could be com‐ pletely tied up wearing only one hat. Larger company size often corresponds to larger ML teams, but it depends. For example, a large company in a traditionally nontech industry, might have its first ML team hires operate in more of a startup-like environment while they figure out how ML best works for the company. Let’s go one level deeper and add more details of ML or data responsibilities. Figure 1-5 expands on the machine learning lifecycle from Figure 1-4 to reflect teams or companies with more fine-grained roles. (It’s worth repeating that even if this list is a useful and common enough heuristic, it’s still a bit simplified for illustration pur‐ poses since there will always be exceptions and outliers.) Figure 1-5. Machine learning lifecycle with more fine-grained roles (extended version of Figure 1-4 ). Here’s an example of what your role might be responsible for within these more fine- grained roles, as illustrated in Figure 1-5 : • You build the data pipelines for analytics and ML (step A). • You train ML models (step B). • You build the infrastructure for ML models to be deployed (step C.1). • You design and conduct hypothesis testing, often A/B tests, for new ML product features (step C.2). • You do data analysis, build reports and dashboards, and present to stakeholders (step D). Figure 1-5 is often referred to in later chapters, so save or book‐ mark it!"
      },
      {
        "section": "The Three Pillars of Machine Learning Roles"
      },
      {
        "text": "To set the stage for the rest of the book, I’ll go over what I call the three pillars of ML and data science roles: • Machine learning algorithms and data intuition • Programming and software engineering skills • Execution and communication skills These are the broad categories of skills that you will be evaluated on during ML job interviews. This book focuses a lot on helping you understand these skills and bridge any gaps between your current experiences and skills and those under these three pillars (see Figure 1-6 ). All these skills will be expanded on in the following chapters. Figure 1-6. Three pillars of machine learning jobs. You’re able to understand the underlying workings of ML algorithms and statistics theory and their respective trade-offs—which is essential when you’re faced with an open-ended question in a real-world ML project at work. You’re not just following steps as you would for a school assignment. Having data intuition means that when you’re faced with a new problem, you know how to use data to solve it; and when you encounter new data or data sources, you know how to dive in to evaluate them. You ask yourself, is this data suitable for ML? What types of ML models might it be suitable for? Are there any issues with the data before you can use it for ML? You know what to ask and how to find the answers. In the ML job-interview process, various types of interviews and interview questions are aimed at assessing a candidate’s knowledge and readiness in this pillar, which I’ll cover in Chapters 3 and 4 . While working on a project, you have the programming skills required to deliver, such as manipulating data with Python or using an internal deploy process so that another team can use the results from the ML model. Even if you know the theory well, without the programming or software engineer‐ ing sense, you can’t make ML materialize out of thin air. You need to use code to connect the data with ML algorithms, which are also implemented with code—that is, you must convert theory to practice. Other programming skills in high demand for ML roles are the (software) engineer’s ability to transition from prototype to production—that is, the ML is integrated and released. Some roles are responsible for end-to-end ML: from researching and train‐ ing models to deployment and production. Some ML roles, such as MLOps engi‐ neers, are responsible for building software infrastructure that can handle the demands of processing large amounts of data to send ML responses to users in sec‐ onds or even milliseconds. In the ML job-interview process, various types of interviews and interview questions assess a candidate’s skills in this pillar, which I’ll walk through in Chapters 5 and 6 . You’re able to work with people who aren’t in the same role as you. In ML, we work with software engineers, data engineers, product managers, and many other collea‐ gues. The ability to get things done in a team encompasses a few soft skills such as communication and some project management skills. For example, being unable to communicate with team members is a real blocker for projects and could cause your ML projects to languish or even be deprioritized. Even in cases where you work with only one person (say, your boss), you still need to be able to report on your projects, which requires communication skills. Consequently, in the ML field a highly in-demand skill is being able to communicate technical con‐ cepts with nontechnical stakeholders. You’ll also need some project management skills to keep your tasks on track. We all learn to how manage our to-do lists and calendars during the process of education or self-learning, but it’s more chaotic since now your project calendar depends on oth‐ ers’ calendars and priorities. Even if you have a project and/or product manager to keep the team on track, you still need to manage yourself to some extent. Without soft skills, things don’t get done, full stop. Don’t be that candidate who focu‐ ses only on technical skills but neglects building and demonstrating their soft skills in interviews. I’ll delve into the details of how ML interviews evaluate candidates on this pillar in Chapter 7 . Growing your skills in all three ML pillars is a tall order, and for entry-level roles you’re usually only expected to have a minimum (such as a 3/10) for each pillar, as illustrated in Figure 1-7 . For example, a job candidate who has some exposure to pro‐ gramming, even if they aren’t skilled or experienced, can be taught to improve. Ideally, you’d be stronger on at least one pillar (such as 5/10 for programming) that is most related to the particular ML role in order to stand out from other job candidates. Figure 1-7. Minimum required skill levels for ML jobs (example). For senior roles, the bare minimum requirements are higher, but a similar rule of thumb applies: clear the minimum skill requirements. From then on, you’ll be com‐ pared with other candidates on the skills that you are great in, depending on the role. Data scientists who only train ML models but don’t deploy them might not need to develop their programming skills as much as their ML theory and communication skills. For entry level roles, I’d argue that the communication pillar has a lower requirement (but not 0/10, please!) because it takes the hard-earned experience of working with a larger group of people, including nontechnical teammates, to raise it higher. This also gives some candidates an edge in this pillar: for those with a nontraditional back‐ ground, such as candidates who are self-taught or switching from software engineer roles or another field, the ability to adeptly tell a story and showcase a portfolio can set them apart from other candidates. Now that you’ve had an overview of the three pillars, you can use this mental model to stand out."
      },
      {
        "section": "Machine Learning Skills Matrix"
      },
      {
        "text": "Congratulations! You’ve made it to the end of a pretty dense section! Now that you’ve gone through the overview of the machine learning lifecycle and three pillars of ML skills, it’s time for you to map your interests and skills to job titles. Table 1-3 will give you a rough idea of what skills you will need to learn in order to succeed in specific roles. On a scale from one to three stars, one star represents a skill of lower importance, and three stars represents a highly important skill. Table 1-3. Machine learning and data skills matrix Table 1-3 is often referred to in later chapters, so save or bookmark it! Taking a look at these skills, you can roughly map them to the three pillars of ML skills in the previous section, as shown in Table 1-4 . Table 1-4. Machine learning and data skills mapped to the three pillars of ML jobs It’s OK if you aren’t completely sure what each type of skill might entail just yet. In Chapter 2 , we will revisit this matrix, and there will be details and a checklist for self assessment. You don’t need to worry about every single skill; companies are aware that they are responsible for training up new grads. But you can stand out from other job candi‐ dates by showing that you are more easily trainable and can learn fast. An easy way to demonstrate this earlier in your ML career is to gain high-level (not necessarily deep) exposure to topics that you don’t have experience with yet. For example, even if you haven’t worked much with version control, it’s a bonus to be familiar with. You can achieve this by watching some videos (30 minutes) and installing/testing it out on a project (one hour). Now, let’s tie all this together. We’ve looked at the machine learning lifecycle ( Figure 1-5 ) and machine learning skills matrix ( Table 1-3 ). What’s left is to see what jobs are best for you to apply to now or to gain the skills for! To do so, let’s connect everything to the current trend of ML and data job titles ( Table 1-2 ). This is illustra‐ ted in Figure 1-8 . Figure 1-8. Common ML job titles and how they correspond to the ML lifecycle. The alphabetical annotations in Figure 1-8 can be mapped to those in Figure 1-5 , lis‐ ted here for convenience: • (A) Data • (B) Machine learning development • (C.1) ML/software infrastructure • (C.2) ML hypothesis testing/monitoring • (D) Reports and dashboards Figure 1-8 is often referred to in later chapters, so save or book‐ mark it! When you see a job title and check the details of the job posting, you can map it to what that job is likely responsible for in the day to day. In addition, based on what part of the ML lifecycle you’re interested in, you can better prepare and target your job applications, so you don’t accidentally bark up the wrong tree. Go to a job board of your choice, such as LinkedIn, Indeed, or others listed in Chap‐ ter 2 . Search “machine learning,” “data scientist,” “data,” “AI,” “generative AI,” and so on. What are you seeing? Do you see different types of jobs being advertised that all use ML?"
      },
      {
        "section": "Introduction to ML Job Interviews"
      },
      {
        "text": "Now that I’ve introduced many job titles that might be of interest to you, it’s time to go through all the steps and types of interviews you will encounter during the pro‐ cess! This book is called Machine Learning Interviews , but interviews are so much more than just interview questions. There are job applications and your resume, which are how you get interviews in the first place. If you don’t increase your chances of getting more interviews, then you won’t even get the chance to answer any inter‐ view questions! I’ll be covering the process from beginning to end, including how to follow up after the interview ( Chapter 9 ). To quickly set the stage, here are some common terms used in this book. When I use the term “interviewee,” I am referring to the person currently seeking employment, while the “interviewer” is currently employed at the company that the interviewee is interviewing to join. The interviewee is also referred to as a “candidate” or “job candidate,” since they are a candidate to be the successfully hired person (see Table 1-5 ). Table 1-5. Synonyms of common terms used in this book “Big tech” refers to the major, large tech companies. Because of constant changes in the industry—for example, Facebook rebranding to Meta as the parent company and Google doing something similar with Alphabet—the popular FAANG. (Facebook, Apple, Amazon, Netflix, Google) acronym has already become outdated. To keep things simple, I will use the umbrella term “big tech.”"
      },
      {
        "section": "Machine Learning Job-Interview Process"
      },
      {
        "text": "Now let’s get into the entire job-interview process. You’ll start by applying to jobs, then interviewing, and then, after some rounds of interviewing, finally receiving offers. This process is detailed in Figure 1-9 . Figure 1-9 is often referred to in later chapters, so save or book‐ mark it! Figure 1-9. ML interview process. Let’s imagine that you’re just starting out and applying for an ML role at a company with an established HR and hiring process. You can begin your application in a few ways: by cold applying through the company website or job board (discussed in Chapter 2 ) or through a referral from someone within the team or company. You can also get interviews through cold messaging on LinkedIn or by emailing recruiters. Usually, at companies that have an HR-tracking software system, even if someone refers you, you’ll still need to upload a standard application into the online portal, which means you’ll need to prepare an updated resume and fill in your information. You may also choose to supplement your job-search efforts by working with a third-party recruiter, which is different from an in- house recruiter who works or contracts specifically for the hiring company. Third-party recruiters often work with multiple compa‐ nies at once. Professional peers I know recommend working only with specific trusted third-party recruiters but warned me to beware those who make too many unrealistic promises or aren’t reputable. You can read more about third-party recruiters in this Forbes article . Using the first method—cold applying through company websites or third-party job boards—you’ve been browsing job boards like Indeed as well as going directly to the career pages of companies you’re interested in working for. In this scenario, you don’t have someone referring you to the team or company (I’ll cover that in “Apply‐ ing via a Referral” on page 22 ). You’ve seen some ML-related jobs that seem relevant to you, and you clicked the links to apply. After you submit your application and the company has your information and resume, an HR member, recruiter, or whoever is in charge of resume screening, will proceed with the next step. The reality is that jobs have many applicants, and you should assume the first batch of applicants will be filtered before the hiring manager sees them. The hiring manager is the manager you’ll work with and report to if you join the team. So you can usually assume that a generalized HR partner or internal or external recruiters will be read‐ ing your resume first. These recruiters may be somewhat familiar with the roles they are screening resumes for, but they are still predominantly generalists, not as special‐ ized as the engineers and ML professionals you’ll actually be working with. This part of the screening process leads to several hidden criteria for your resume, which is why it might be baffling when your resume doesn’t clear this step even if you have a relevant background. It’s important to remember that these generalists will likely pass along your resume to the hiring manager if they: • See key technologies or experiences on your resume based on the job posting • See years of experience in key technologies or experiences or, in the case of entry- level or new-grad jobs, sufficient evidence that you can be easily trained • Understand that your skills and accomplishments are relevant, in plain language To determine whether your resume meets the criteria, the recruiter will likely be searching for keywords and comparing your resume to the job posting. They will not automatically “translate” skills on your resume for you. For example, if the job description says “Python” and your resume says “C++,” at this step they will likely not consider that, since both programming languages are object oriented, you could probably learn Python quickly if you put in the effort. There has been some debate at this stage on ATS , which is an acronym for applicant tracking system . While companies do use systems such as Workday to manage appli‐ cations, there hasn’t been concrete proof that companies are using them to program‐ matically filter out resumes at this step for each job posting ( Figure 1-10 ). Figure 1-10. Gergely Orosz (founder of The Pragmatic Engineer publication and former manager at Uber) on ATS (screenshot via Twitter). In practice, recruiters use them at most to filter resumes into a selection to fulfill existing criteria on the job posting, such as those mentioned on the previous page. I also haven’t seen ATS automatically filter out qualified candidates during full-time work experience, and once I was responsible for manually reading a PDF containing more than 50 resumes. However, I don’t want to claim that automated ATS rejections are fully untrue. To be safe, in this book I assume both standpoints have some truth to it. So even if ATS is an issue, the steps in this book will help you, since I’ll teach you the principles for how resume selection is conducted. (You can read more on ATS on thetechresume.com .) If you’re able to describe your experiences at a level that HR recruiters can under‐ stand is relevant to the job posting, you will increase your chances at the resume- screening step. HR and recruiters, by nature of the role, are aware of higher-level technologies and what’s popular with the roles they’re hiring for but not the details, so it’s important for your resume to be optimized well. (Read more on how to opti‐ mize your resume in Chapter 2 .) Now that I’ve walked through cold applications directly via job boards or websites without any referral, I’ll provide some examples of how referrals can help you fast- track the process. Let’s say you’re interested in an ML job at ARI Corporation. You know an alum of your university who works on the ML team. You catch up with them and express your interest in the job. During the chat, you show the alum some of your personal ML projects, which are relevant to the ML job you’re interested in. The school alum agrees to refer you and gives you instructions for how to be referred, something that depends on the way the HR system of the company is set up. Since this alum knows you and is willing to vouch for your skills after seeing your personal projects, you get your resume to the “top of the pile.” Depending on the strength of the referral/recommendation, you may skip the resume screening alto‐ gether and get a highly guaranteed callback from a recruiter or even bypass the recruiter directly and get to the rest of the interview rounds. This is illustrated in Figure 1-11 . Note that I say “highly” guaranteed here since it still depends on various factors such as timing. As an example: maybe you got referred, but the job posting has coincidentally just been filled. Thus, you didn’t get to the rest of the interview. I will cover more on referrals and how to get them via professional networking in Chapter 2 . Figure 1-11. The interview process can be shortcut with a strong referral. You’ve been invited to an interview! How do you perform your best? Maybe time is limited; what do you do to ensure that you can maximize your outcome? My personal tactic is to first narrow down the types of questions that might be asked. For example, in the first round of an Amazon interview, the recruiter has outlined the format and it will focus on statistical theory questions. I will read online resources, skim over my notes, and see what topics I’m the weakest on. I will focus less on the questions that I know I can answer confidently and more on those that seem more likely to be asked but that I don’t know well. As to how I “guess” what will likely be asked, that is based mostly on conversations with the recruiter and my follow-up questions to the recruiter or hiring manager. I’m not super accurate at guessing, and this is similar to trying to guess what will come up in a university exam—it could work well, or it could backfire! Either way, there’s the trade-off between knowing a subset of questions well or know‐ ing all questions roughly but not as well (depth vs. breadth). When reviewing my preparation notes, I personally go for breadth, but your results may vary depending on how well you know the material already. Depending on your location and your interviewers’ location, there may be time zone differences. I try to find the time when I have the most energy possible. Sometimes the available interview time slots aren’t ideal, so I choose the lesser of the evils (for example, interviewing from GMT+8 and talking to someone in GMT-4 while travel‐ ing abroad). To make it easy to figure out time zones for candidates invited to an interview, it’s common for HR-scheduling software to have a calendar feature where you can input your preferred times and it will account for your local time zones. However, sometimes the time will be set via back-and-forth emails, and tools such as Cal‐ endly or Cal.com can help. As both an interviewer and interviewee, I am wary of scheduling right at the begin‐ ning of a workday. This is so that I have more time to prepare after I wake up. But of course, if no other time slots are available, then I will select the early time. As an interviewer, I’ve seen countless candidates’ interviews start late because of con‐ nection issues or using a new web-conferencing software—for example, not being able to set up Zoom on time because they hadn’t used it before. As a candidate, I’ve been tripped up and wasted time when needing to use Microsoft Teams because on my personal computers I only had Zoom and Google Meet. In the end, I used the browser version, but there was an issue with my login since my Microsoft student account had expired. We finally got it sorted out, a few minutes later. This could have been avoided if I had tried to sign in a bit earlier or on the day before the interview. Here are some tips to help your interview go more smoothly: Try your best to be in a quiet environment. Some software, such as Zoom, has pretty good built-in noise canceling, as do some wireless headphones. Check your audio and video beforehand. Video-wise, make sure the lighting is good and your camera lens is clean. Sound- wise, make sure your mic sounds clear. On Windows and Mac, there are built-in camera and voice recording apps that I use. You could also start a new Zoom, Google Meet, or Teams session and run a test. Keep a mental list of backup options. Did the internet at your home suddenly go down before the interview? Is there a nearby cafe with (preferably secure) internet that you could go to? Can you use your phone data? Are there dial-in options via phone on the calendar invite? Knowing these things beforehand can help you a lot. I’ve had to dial in once to an interview, and thankfully, I knew that I had the option to. Congrats, your resume has made it past the resume screening! Now let’s go through an example to illustrate what might happen next. Let’s imagine that there were 200 applicants for the role. The recruiter has gone through them and removed 170 that either lacked relevant experience or for some reason didn’t seem to fit the role. Recall that this is based on the impression your resume gave the recruiter; it’s possible that with the same job title and same recruiter team, an improved resume would have passed. If you had a good referral, your resume might have already moved forward. Now that there are 30 applicants, the recruiter will call each of them; this is usually a shorter interview, 15 to 30 minutes long. We refer to this as the “recruiter screening” or “recruiter call.” Generally, the recruiter wants to see what you’re like as a person and if you’re easy to work with. If someone blatantly claims to have experience that they don’t, the call could reveal fabricated work or school experiences. There are other logistical issues to screen for, such as location, salary expectations, and legal status. The recruiter screening is more of a “smell test” instead of an in- depth test of your technical skills and experience. My tip for success is to optimize for one thing: that the recruiter understands that you are a good candidate, that your experience is relevant (or you can learn fast), and that you can fit well into the team and role they are hiring for. This is different from con‐ vincing a hiring manager of the same things, or an interview panel of senior MLEs. Instead, you will succeed here if you make the additional effort to connect your resume to the job description on this call. Here’s an example of some bullet points in a job description: • “The candidate has experience with recommender systems.” • “Experience with data processing such as Spark, Snowflake, or Hadoop.” • “The candidate has experience with Python.” A bad example of explaining your experience on the recruiter call for this job is: “For that past project, I used the ALS algorithm, which was implemented with PySpark.” A better example of explaining your experience on the recruiter call for this job is: “For that past project, I used the alternating least squares (ALS) algorithm, which is a recommender systems algorithm based off of matrix factorization, and I used PySpark, which is Spark that’s wrapped with a Python API.” Note that the italicized phrases also appear in the job description. The better example allows a recruiter to match up more of your skills to the job description, whereas the bad example doesn’t match up to the posted skills in an obvious manner. When you’re writing your resume, you have limited space; the real- time conversation of an interview is a chance for you to fill in gaps that the recruiter may not have noticed. It’s also important to expand on acronyms. This is true for interviews conducted with technical people too. I’m relatively specialized in recommender systems and rein‐ forcement learning, but I don’t work with computer vision tasks in my day-to-day work. I appreciated it when a candidate I interviewed was talking about computer vision projects and generally explained the more niche techniques. You can (and should) do this in a way that’s not condescending to your interviewer, whether they are a recruiter or part of your future team. The recruiter call is a good time for you as the candidate to assess the job as well. You can ask questions that you care about, to see if you should continue to interview. For example, I might ask about the team size and if this job focuses more on ML or data analyst responsibilities. You can also prepare some questions about the company and their products. For example, is the team’s current project focused on improving the click-through rate or long-term engagement? If you’re a user of the product, you might have a lot of ideas and questions to discuss. This is also a chance to show your enthusiasm and knowledge of the company. On to the next step. Good news: the recruiter cleared you! You explained your previ‐ ous experience well, and the recruiter was able to understand your past work and how it connects to the job description they have on hand. But it’s not over yet. You’re among 15 other candidates who succeeded at the first recruiter screening. The recruiter informs you of upcoming technical interviews which include ML theory, programming, and a case study interview. There are also behavioral interviews sprinkled throughout. If you pass those, you’ll make it to the on-site interview, which is often the final round. These days, there are also virtual on- sites/final rounds. If you pass the final round, you’ll be extended an offer. Let’s break down the various types of interviews that take place after the recruiter screening, the first being technical interviews. Technical interviews are typically con‐ ducted with technical individual contributors (ICs), such as an MLE or a data scientist. There may be multiple rounds of technical interviews; there could be one that is a data-focused coding round or one in which the interviewer presents some fictitious example data and asks you to use SQL or Python pandas/NumPy (sometimes there are multiple questions, and you use various programming tools throughout the inter‐ view). I’ll expand more on this type of interview structure and interview questions in Chapter 5 . Apart from ML and data-focused programming interviews, you might be asked brainteaser-type questions. For this type of interview, you might use an interview platform such as CoderPad or HackerRank, where the interviewer presents you with a question and you code in the online integrated development environment (IDE) that both you and your interviewer can see in real time. Sometimes you’ll get other formats, such as technical deep dives, systems design, take-home exercises in a pri‐ vate repo or Google Colab, and so on. I’ll elaborate on how to prepare for these types of interviews in Chapters 5 and 6 . These subsequent interview rounds could further reduce the number of candidates before the final round. In our example, fifteen candidates passed the recruiter screen, and eight passed the first round of technical interviews. After the second round of technical interviews, we’re left with three candidates who will proceed to the on-site interview. Interspersed during the interview process are questions meant to assess how you react in certain situations. The intent often is to use past experience to predict future performance and understand how you react to high-stress or difficult situations. In addition, these questions assess your soft skills, such as communication and team‐ work skills. You’ll want to prepare a few past experiences and relay them in a story‐ telling fashion. For example, during your first recruiter call, the recruiter might ask about a time when you dealt with a difficult timeline on a project. Once you’ve responded you won’t be out of the woods yet. During the on-site, an hour is often dedicated to behavioral questions. And in some technical interviews, you might be asked a couple of questions that are a mix between a purely technical question and a behavioral question. I’ll help you succeed with behavioral interviews in Chapter 7 , which also has tips on company-specific preparation, such as Amazon’s Leadership Principles . For many companies there is an “on-site” final round or the virtual equivalent. These are usually back-to-back interviews. For example, starting in the morning, you might meet with a technical director for a case study interview and then a senior data scien‐ tist for a programming interview. After a lunch break, you might meet with two data scientists who ask about ML theory, and then the hiring manager asks more behavio‐ ral questions and probes about your past experiences. In addition to technical inter‐ viewers, you may speak with a stakeholder (e.g., a product manager on an adjacent team that the team you’re interviewing for works closely with). In several final-round interviews I’ve been through, there was a product manager interviewer or someone from another department that the ML team worked closely with, such as marketing or advertising. Some companies will have an additional mini round after this, such as a quick chat with a skip level (your manager’s manager)."
      },
      {
        "section": "Summary"
      },
      {
        "text": "In this chapter, you’ve learned about various ML roles, the ML lifecycle, and the dif‐ ferent responsibilities that map onto the ML lifecycle. You’ve also seen how you make your way from the beginning of the process to the final round of interviews. There’s a lot to prepare for and to learn about, but now you have an overview and hopefully some thoughts on how you can target your preparations. Now that this chapter has set the foundation, I’ll walk through a detailed job applica‐ tion guide, including a resume guide, to help you greatly increase your chances of getting interviews."
      }
    ]
  },
  {
    "chapter": "CHAPTER 2",
    "title": "Machine Learning Job Application and Resume",
    "content": [
      {
        "text": "To successfully land job offers in the field of machine learning, not only do you have to prepare for the interviews themselves, but you must first get interviews. During the application process, there are many opportunities to make your profile stand out from the crowd and increase the number of interviews you get. If you are currently struggling with getting callbacks from your applications, this chapter teaches you how to optimize your applications for much better and relevant results. If you’re just starting out, this chapter provides an in-depth walkthrough of the process that will help you avoid mistakes going in."
      },
      {
        "section": "Where Are the Jobs?"
      },
      {
        "text": "You want to find an ML job, but where? You may know of online job boards such as LinkedIn or Indeed, but there are other places where I and countless other ML pro‐ fessionals have found jobs, too. Table 2-1 provides a list of additional job sites and informal methods of learning about job listings. Table 2-1. Methods for learning about job listings with examples"
      },
      {
        "section": "ML Job Application Guide"
      },
      {
        "text": "This section will walk you through choosing a strategy for applying for jobs, and the following resume guide will help you create an optimized job application. Some folks have had success getting jobs without any networking. In fact, my second job was a cold application; I didn’t know anyone working at the company at the time. But from a probability standpoint, I would need to send out more applications and do more interviews if I applied only to companies where I didn’t have any referrals. The following is a mental equation I use to assess this: The more applications you send out, regardless of EPA, the more you increase your chances of getting an interview. Indiscriminately sending out a vast number of appli‐ cations—a “spray and pray” approach—might be able to make up for a low EPA. On the other hand, if you want to have the same number of interviews but submit fewer applications, you’ll need to increase your EPA on average. Filtering through job postings for suitable ones or tailoring your resume can increase your EPA. You’ll need fewer applications to get the same number of interviews (most of the time). So which type of strategy should you choose? You don’t have to get referrals or tailor your resume, but be prepared to send out more applications in this scenario. It’s your choice! If you prefer the mass-application approach, feel free to skip the following sections, though I recommend reading them. Here are some strategies to increase your EPA, which I’ll elaborate on in the follow‐ ing section (see Figure 2-1 ): Get job referrals. Get referred for ML jobs and use networking to increase your chances of being referred. Vet jobs before applying. If you invest the time to find and apply for jobs that your skills are more suitable for, that can increase your EPA. Tailor your resume. In conjunction with vetting jobs, you can rearrange your resume to highlight keywords and skills that are most relevant to your target jobs. Figure 2-1. Job applications and their effectiveness per application. I have had good success applying to jobs that I’ve had referrals for, but does that mean I apply only for jobs when I have a referral? To be honest, no. I also send out resumes for jobs that may not be the best fit, and do not always tailor my resume. You don’t have to maximize your EPA for every single application, but as long as you are getting some referrals, you are increasing your EPA on average. You can mix and match depending on your time commitments; sometimes I just don’t have the time or energy to reach out to someone to ask for a referral, or don’t feel that I know the connection at the company well enough to ask. So I just cold apply. In Chapter 1 , I mentioned that job referrals can help you rise to the top of the “stack of resumes” or even guarantee that you get a recruiter call. In some cases, if you’re a referred (i.e., recommended) candidate, you can even bypass the initial recruiter call and skip to a later stage of the interview process, as illustrated in Figure 1-11 . In this chapter, I mention how referrals are one way to improve your EPA. I personally think it’s great to make use of referrals when possible. This does require that the per‐ son referring you is willing to put their reputation on the line, because by referring you, they are suggesting that you will be successful once you are hired. The following are three examples, with screenshots, of reaching out for referrals, cof‐ fee chats that led to a referral, and informational interviews. A common misconception is that referrals are a silver bullet to get‐ ting hired. This is not true since a referral often only gets you through the first round of the process; the rest is up to you. The subsequent interview rounds will still put you through the wringer. Here’s an example of an intern candidate I once referred to my team. We had met when he attended an ML journal club meetup that I had coorganized called AISC ( Figure 2-2 ). After another event I hosted, I reached out to him because he had pre‐ sented a great five-minute “lightning” talk. We had a brief back and forth that con‐ cluded the conversation, after which we didn’t speak for another two years! Figure 2-2. Referral example 1: brief conversation after meeting at an ML journal club. Later, in 2022, he reached out to me to chat about a role in the company where I was working. Since I recognized him from when he attended the ML journal club a few years ago and remembered our conversation, I gladly referred him ( Figure 2-3 ). Figure 2-3. Referral example 1: referring an intern job candidate. This is a good example of reaching out when you’ve known each other and are pro‐ fessional acquaintances, which could result in a referral, interview, or job offer down the road. Here’s another example of a “warm” outreach ( Figure 2-4 ). This person messaged me, mentioning a conference we had both attended. We had spoken only briefly at the conference, but even that mention was enough to get my attention in a crowded inbox. I agreed to have a quick call and answer some questions about the job posting. Figure 2-4. Referral example 2: warm reachout to ask about a job posting. During the call, I asked the person about their past experiences. After hearing about their relevant data experience, I offered to refer them before they explicitly asked ( Figure 2-5 ). Figure 2-5. Referral example 2: A message where I referred a job seeker. Here are some reasons I agreed to speak to the candidate and to refer them: State a connection. They stated where they had met me before. In some cases, job seekers mention reading my blog or seeing me speak. They may mention something as simple as seeing one of my LinkedIn posts (it’s important to be specific about which one). Be specific. They linked the job posting or mentioned details about why they were reaching out. Sometimes I get very broad questions, such as “How do I enter data sci‐ ence?” In those situations, even if I have a coffee chat with them, I’ll be duplicat‐ ing and repeating information that they could get in one of my blog posts, or from this book! A call or meeting should be meant for a deeper conversation. Politeness goes a long way. They weren’t pushy or rude and were very respectful of my time. The intern candidate in job referral example 1 also demonstrated these traits in their reachout. Here’s an example where someone I hadn’t met before reached out for a coffee chat ( Figure 2-6 ). Note that she mentioned seeing a specific LinkedIn post I wrote, which echoes the tip to state a connection with the person you’re reaching out to. This mes‐ sage was for a general chat, not a specific job posting, but the fact she brought up both AI and game development, which are specific niches I’m interested in, was enough to prompt me to set up a meeting. This was relatively easy to do as we were both based in the downtown Toronto area at the time. Figure 2-6. Referral example 3: coffee-chat request. During the meeting, we chatted in depth about various ML and AI topics and game development, which gave me the confidence that this was someone I could keep in mind to refer. In fact, my team was hiring at the time, which I mentioned. Sadly, she had recently started a new job, so I wasn’t able to refer her, but in an UNO Reverse situation, she offered to refer me to her new employer ( Figure 2-7 )! Figure 2-7. Referral example 3: UNO Reverse referral offer. As you can see from these three examples, you can get referrals with a thoughtful message. Attending events and conferences can increase the number of warm con‐ nections you can reach out to when the time comes. Many experienced leaders in the industry are proponents of referrals. Here are some examples: So, how do you “network”? When I was a student, this term greatly confused me. “Say I go to conferences and meetups, so what? People don’t want to refer me to jobs just by meeting me once…” If you think that, then you’re probably right—people usually won’t refer you unless there’s a reason for them to do so. Luckily, many companies, especially big tech and larger companies, give referral bonuses. This means that if an employee refers someone who gets hired, they receive money or rewards. Usually, there is a requirement that the new hires have to stay for six months or so to prevent abuse of the reward system. Referral programs incentiv‐ ize employees to find people in their networks to refer to job openings. In addition, ML is in high demand, so some companies even struggle to hire. Many companies and teams source qualified candidates through referrals from friends, for‐ mer colleagues, university peers, and more. So even if you don’t have a strong net‐ work (yet), people do have an incentive to keep an eye out for suitable job candidates. These are the steps I use: 1. Look at meetups, conferences, and the like happening in person or online. 2. Go to events (usually free). 3. At each event, meet just one new person. With this small goal, over time you will meet more people working at various compa‐ nies. Even if you go to only one event per month, over the course of a year you will have met 12 people who may be willing to vouch for you when you apply to their employer in the future. Or you may even meet startup founders who can hire you more easily because they know you. Networking is a long-term investment, and the rewards will appear over the long- term horizon. One misconception that people have is that networking only encom‐ passes this scenario: you first find some jobs you’re interested in and then reach out to people related to that company or job. If you’re networking only when you’re already applying, you will be stressed out and stretched thin on time—not to men‐ tion, it might be too late. If you’ve been meeting people and know people from other companies, or even alumni from your university, bootcamp, and so forth, you can reach out when you see a job posting at their company. If you aren’t sure how to start, refer to the suc‐ cessful examples in the previous section. Even if you don’t think you’re “good at” meeting new people, it’s a skill that can be learned and practiced. Set the small goal of meet‐ ing just one new person when you go to any networking event, meetup, or conference. It really adds up. Beyond getting referrals, there are strong benefits of networking. Here is an example from when I was a new graduate: I met two final-round interviewers (director level) at two different companies before I even applied to their job postings, merely by attending conferences and meetups. I got both offers. Neither of them referred me, but I still got the benefit of networking since both had interacted with me at some point; they were warm connections, rather than interviewers I was meeting for the first time in the interview."
      },
      {
        "section": "Machine Learning Resume Guide"
      },
      {
        "text": "I mentioned tailoring your resume as a way to increase your EPA, but whether you plan to tailor your resume or not, you’ll still need at least one version of it. This sec‐ tion will guide you through creating your first resume. If you already have one, you can skim this section for tips and best practices, then head to the part where you tai‐ lor your resume or other sections you’re interested in. Before you start writing your resume, you should jot down an inventory of what you’ve done in the past. This inventory includes past work experience, ML projects at school or at work—anything that could be relevant to ML and data science. If you don’t have any personal or school projects or work experience outside of ML, you can still take an inventory; this will help you figure out what else you need to learn to close the gap between your current skills and your target ML role. As an example, when I was a new grad (with less than one year of working experi‐ ence), my inventory looked like this: University • Econometrics research paper about video game prices on Steam, with data I scra‐ ped myself • Econometrics research paper about Reddit engagement, with data I scraped myself First full-time job • ML churn model I built Write down a list of jobs or major projects (school, personal, etc.) that you’ve done. Feel free to focus on ML-related ones, but at this stage, anything loosely related can count. (Did you do data cleaning? Use Python? Add it.) Include your education, cer‐ tificates, anything relevant. These don’t have to be in resume-bullet form; they can just be an unformatted text list or jotted on a notepad. Set a timer for 30 minutes, do it, and come back. This book will miss you but needs you to do this! From the inventory that you listed in “Exercise 2-1” on page 37 , pick three to five experiences you feel are most relevant to ML roles in general. Refer to Table 1-3 , the ML and data skills matrix, again. For your targeted ML roles, are the experiences on your list relevant so far or not? If you feel that you don’t have three relevant ML or data experiences, you can temporarily pad out three experiences with the work or school experiences that were the most substantial and “impressive.” Don’t worry about it being perfect at this stage; you can always go back to your longer inventory and pick another one later. Next, list everything you did related to those top three experiences: this includes not only technical parts related to coding, ML, or data but also soft skills, such as present‐ ing the results to your team or organizing a group chat to coordinate teammates. To continue using the example from my own initial, unrefined inventory, here’s what I would include: University student experience example Econometrics research paper about Reddit engagement, with data I scraped myself • Scraped Reddit with Python • Cleaned data with Python • Performed statistical modeling with Python, Stata • Visualized results with Python • Created presentation of project with LaTeX • Presented project overview and results to seminar class of 10 people and professor First job (less than one year experience) example My first ML churn model • Exploratory data analysis (EDA) with SQL, Python • Cleaned data with SQL • Trained logistic regression model with SAS on tabular data; created ensem‐ ble model in SAS • Ran model evaluation and analyzed results with SAS, SQL, Python • Created simplified and cleaner visualization to use in presentation with Excel, PowerPoint • Presented the results with PowerPoint • Collaborated with ML engineer to put the model in production From the list of past experiences you wrote down in “Exercise 2-1” on page 37 , pick the top three to expand on as in the previous example, writing out everything you did related to them, including your use of technical or soft skills. Now that you have a starter list of your past experiences to refine, let’s look at the sections of a resume. These are the core sections of your resume: • Experience • Education These are optional sections: • Skills summary • Volunteering • Interests • Other sections (your name of choice) Don’t worry about filling in the optional sections yet; doing so will depend on what you have in your core sections and whether they are already lengthy. Use the top three experiences you provided in your inventory for “Exercise 2-1” on page 37 . You should also gather the following pieces of information: • Job title • Place where you worked • Time frame you worked there (e.g., May 2018 to November 2021) • Bullet points of your responsibilities from “Exercise 2-2” • Any other information that might be expected in your region, industry, or work culture An example of a section of your initial resume might look like this: Data Scientist, ARI Corporation (May 2021 to Present) • Design and develop collaborative filtering models for web page personalization • Develop ETL production code that aggregates predictive model scores according to user specification • Develop predicting ensemble model to optimize marketing campaign planning and touchpoints You don’t need to format your resume in a template just yet; it’s more efficient to pin down the contents first before you deal with formatting (sometimes adding just one word breaks your beautiful layout and you spend more time than it’s worth to fix it…). Note that I’ll link to some common templates at the end of this section. Here are some more tips to improve your initial bullet points: Use action verbs to start the sentences. For example, instead of writing “Image recognition with TensorFlow,” write “ Developed image recognition model with TensorFlow.” (The action verb is itali‐ cized for illustration; you don’t need to italicize it on your resume.) This can help clarify what you did during your experience, not just the outcome (which was likely a team effort). You can find a larger list of action verbs from the University of Washington: Action Verbs for Resume Writing. Specify your impact, ideally in a way that’s quantified and easy to understand. [ Original ] Design and develop collaborative filtering models for web page personalization [ Modified ] Design and develop collaborative filtering models for web page per‐ sonalization, resulting in 2x engagement rates compared to baseline Add tools and programming languages you used. [ Original ] Design and develop collaborative filtering models for web page personalization [ Modified ] Design and develop collaborative filtering (ALS) models with PySpark and MLlib for web page personalization, resulting in 2x engagement rates com‐ pared to baseline At some point, the word count might become too long, and you’ll have to cut down on what you’ve written. Tinker around with the wording to see what the most essen‐ tial information is to keep. The points here are pretty similar to the Experience section; you should also include the following pieces of information: • School/institution you attended • Location, country (optional but recommended) • Time frame when you studied there (e.g., May 2018 to November 2021) • Bullet points of major projects and assignments related to ML or data • Any other information that might be expected in your region, industry, or work culture The following is a example of what this section might look like: University of Waterloo Waterloo, Canada, 2010–2015 • Scraped and cleaned sales data with Python, pandas • Forecasted video game prices with ARIMA time-series model Now that you have the core sections, take a look at the optional sections. Do you have a lot of projects and experience in your core section? If you do, then you may not have space to add volunteering. For example, when I was a new graduate, I added a skills summary and volunteering experience section to pad out the space since I barely had any experience. If you have other experience, I suggest that you focus first on refin‐ ing your existing bullet points before you start padding your resume with irrelevant content. Too much additional content might only serve to distract recruiters and hiring managers from noticing the most crucial and important skills that you have. Take a look at your Experience and Education sections so far. Do they look robust and relevant enough for any of the target roles in Figure 1-8 ? Are there any bullet points that your peers interested in ML have but that you’re missing? Don’t worry yet—we’ll create an action plan at the end of this chapter and throughout this book. The point here is to start self-reflecting and connecting your experiences to the ML jobs we talked about earlier. For now, are there any volunteering experiences, inter‐ ests, or additional experiences that you have that are relevant? Write them down. The skills summary is a place to list a bunch of programming languages and frame‐ works you have had exposure to. Beware: don’t exaggerate too much; if you list a framework or library here that doesn’t match up with what you’ve elaborated on in the bullet points, the technical interviewers might ask you to elaborate. Everything you’ve listed on your resume is fair game to ask about. Here’s an example: Skills summary • Python • TensorFlow, PyTorch • NumPy/pandas, Polars • C++ • And so on… When I review resumes, I tend to skip this area and go straight to the work experi‐ ence bullet points. However, this may vary depending on the reviewer; a skills section might be more relevant to a recruiter who’s trying to match off of the job description, for example, and the more you have listed there, the more likely there will be overlap with a job description. For this section, you can just use bullet points on one line instead of grouping them under an experience unless (1) your volunteering experience is very impactful and substantial, in which case I might just put it under the Experience section, or (2) you’re really trying to pad out your resume. Here’s an example: Volunteering experience • Volunteer, SIGIR Conference 2023, Taipei • Volunteer, Toronto Machine Learning Summit, 2020, Toronto • And so on… Some people recommend including this section to show that you have some interests outside of work. In my opinion, the general rule applies that if you don’t have space, you can drop these optional sections without consequence. On the other hand, you can keep it if your interests are something cool like chess grandmaster or equestrian cup title holder—whatever you’re proud of. When I was a student, I padded this area with the following: Interests • Team Fortress 2 scrap trader, 2012–2015 • AISC (formerly Toronto Deep Learning Series) blog editor, 2019 • And so on… Yes, I put video-game-related interests in my resume. Yes, I did trade scrap metal, an informal online currency in Team Fortress 2, an online game. There’s a whole econ‐ omy around it. Yes, it was really because I had to pad the space and for no other rea‐ son. However, no one asked me about it. You can choose to add other sections, which pretty much follow the same format as the Volunteering and Interests sections. I encourage you to do this if you have nota‐ ble interests, volunteering, and whatnot that would make more sense to rename under their own sections. For example, once I started public speaking, I had enough entries to warrant a new section, replacing my Volunteering section on my resume: Public speaking • Keynote speaker, O’Reilly AI Superstream (MLOps) • Keynote speaker, PyCon DE & PyData Berlin • And so on… • “Resume Checklist” to make sure your resume looks polished (University of Waterloo) • Action verbs for when you run out of ideas: “Action Verbs for Resume Writing” (University of Washington) • Resume format and checklist via CareerCup (North America focused) • Resume templates on Overleaf (LaTeX markdown): The one I’ve used for the last five years is AltaCV (two-column). I personalized the template by removing the graphics, leaving only text. A popular single-column template is Modern-Deedy . That’s it for this section. As usual, be sure to check if there are any regional expecta‐ tions for information you should include in your resume. I also have included a resume-related FAQ at the end of this chapter. Now that you have your basic resume, let’s look into how to tailor it for common ML job titles (see Figure 1-8 ). If the job title you’re looking for isn’t in Figure 1-8 , you can map it to the ML lifecycle ( Figure 1-5 ) and use the same tips for similar roles in the ML lifecycle. Recall that you don’t have to tailor your resume for every job applica‐ tion, but even if you do it only for the most common job titles that you are interested in, you can increase your EPA on average. If you refer back to the skills matrix ( Table 1-3 ), you can probably see why tailoring your resume can be useful: if you have “programming tools” and “statistics” skills, you can possibly apply for both DS (data scientist) and MLE roles, but to highlight additional skills that differ between the two roles, changing some bullet points will help market your skills better. The ML skills matrix ( Table 1-3 ) helps you narrow down job titles that fit your past experience better, but from then on, your job search is dependent on the actual job descriptions. Once you start to look at job descriptions, you might sometimes see DS postings that involve skills mapped to the data analyst role (“product” data science), and some‐ times the job posting could map more to the MLE role on the matrix. Head over to the job postings search engine of your choice! I personally like to start with LinkedIn since I’m familiar with the platform, but most jobs from bigger com‐ panies are cross-posted on all the major platforms anyway. Start typing in a few job titles (you can use Figure 1-8 for the common ML job titles as inspiration). Click on ones that catch your eye and look at the job descriptions. Are there any keywords that match up with bullet points on your resume? After browsing some more, note any keywords, tools, or frameworks that show up repeatedly. Do you have that skill, or would it be worth learning so that your resume can match up more closely with those job descriptions? In my own experience, my job title has been data scientist for all of my full-time roles, but I’ve always been focused on building and deploying ML models into a product or improving the ML product. Based on the matrix, I’ve done everything from MLE to applied scientist, and even some MLOps-related roles. Let’s now imagine that I’m browsing jobs online and you’re looking over my shoul‐ der. I’m going to search “Spotify machine learning” and start clicking into the results, beginning with the example in Figure 2-8 . Figure 2-8. Screenshot of Spotify data scientist job posting via LinkedIn. After reading this Data Scientist posting ( Figure 2-8 ), I write down what I think is important: • Cooperation with stakeholders, communication (mentioned multiple times and at the top of the bullet points) • Perform data analysis, using BigQuery or SQL • Some statistical modeling such as linear, logistic regression Next, I’ll look back at my resume experience—for example, the bullet points for a previous job where I made my first ML churn model—and map it to the data scientist posting. If you haven’t finished up your resume yet, you can use the inventory list that you made for “Exercise 2-2” on page 39 . The most relevant out of the points from my first ML churn model (see “Take Inven‐ tory of Your Past Experience” on page 37 ) that I initially wrote down are: • Performed exploratory data analysis (EDA) with SQL, Python • Created simplified and cleaner visualization to use in presentation with Excel, PowerPoint • Presented the results with PowerPoint Based on the ML lifecycle, it feels like this role is more focused on reporting and data analysis (step D in Figure 1-5 ), so I should make sure I am interested in that part of the lifecycle before proceeding to actually tailoring my resume. If I’m interested in applying for this data scientist role, I’ll focus on the three points I listed from the job description and shorten or remove the other bullets. Recall the inventory list you created for “Exercise 2-2” on page 39 ; if you have other experiences more relevant to this job posting, swap them in. If your current resume is pretty rele‐ vant to this job posting, then you can keep it as is. If you do remove some less relevant points, keep an eye out on the space remaining in your resume. How much you remove depends on how much space you have on your resume! I have more experience now so I err on the side of removing more, while early on I chose to pad more points and hardly ever removed points. It’s fine to remove things as long as the core is there; if the interviewers are interested in how I train more complex ML models—a bullet point I removed since it wasn’t on the job description—they can ask me in the interview. Let’s continue to scroll through the search results for “Spotify machine learning” and look at another posting in Figure 2-9 . Figure 2-9. Screenshot of Spotify machine learning engineer job posting via LinkedIn. As with the first example, I read through the Machine Learning Engineer posting and write down what I think is important: • Implementing ML in production • Prototyping • Testing and tooling, platform improvements • Collaboration with cross-functional teams Based on these points, it seems that this role is more focused on ML model training, with some parts on the ML infrastructure, which are illustrated by steps B and C.1 respectively in the machine learning lifecycle ( Figure 1-5 ). If I’m interested in applying for this machine learning engineer role, I’ll focus on these relevant three bullet points and shorten or remove the other bullets. To do so, I’ll look back to the list of seven points from “My first ML churn model” example and map it to the MLE posting. The most relevant points are: • Trained model with SAS • Ran model evaluation and analyzed results with SAS, SQL, Python • Collaborated with ML engineer to put the model in production • Cleaned data with SQL The inventory you created for “Exercise 2-2” on page 39 can be reused for different types of roles without the need to rewrite anything. It’s good to remember that com‐ munication and collaboration skills are also important to companies, and you’ll notice these skills listed a lot in all types of job postings. Don’t forget to include the points where you were collaborating with other teams or presenting your work to another organization in at least one of your resume bullet points. This is especially relevant for folks who think they don’t have enough “ML experience”! Your experi‐ ence analyzing data, as well as communicating it, is important and can strengthen your resume more than you might think. I’d recommend making the technologies you used in your past role very clear in your job experience bullet points. You can list them inline or at the end of a bullet point, depending on the space you have and what is most concise. Otherwise, if you have space, feel free to include a skills section in your resume. Zooming out a bit now that you’ve been head down crafting and refining your resume: the companies and teams you’re applying to have posted this job for a rea‐ son. They have a gap on their team and want someone to fill that gap. Therefore, your application and resume should focus on convincing the hiring com‐ mittee that you are a candidate who can fill that gap and be part of their team. This includes: • Real and relevant experience that you can apply to the job, including transferable skills: skills that aren’t identical but can easily be transferred between domains. • Soft skills—you can work well with people in the team and communicate with broader groups of people, such as product managers, and so on. • Technical skills—you can make individual technical contributions. • Evidence that you can onboard to an existing project or gain enough context to start something new. These skills are succinctly described in the three pillars of ML roles that we explored in Chapter 1 . You can show many skills and experiences in your resume, but not all of them. For example, take a quick look at your resume: does it completely lack any examples of teamwork? Are there other points that could help show you’re a person who can learn quickly (if you don’t have as many relevant working experiences)? If things look good so far, start applying, but if not, take some time to keep improving your resume."
      },
      {
        "section": "Applying to Jobs"
      },
      {
        "text": "Now that you have tailored your resume, it’s time to apply! Head to job boards (you can use the ones listed at the beginning of this chapter for inspiration). I think it’s OK to start applying even if you’re not sure if your skills and resume are perfect yet; if you apply for a few jobs and don’t even get a recruiter callback, that means your resume or skills need to be improved more. You may even find that continuing to improve your resume and spending time on getting referrals are enough to improve your EPA and start getting calls. It’s a learning process, and even if you don’t start out perfect, the goal is to move toward getting callbacks, through the volume of applications you submit or through applications with higher effectiveness. Hopefully, you’ve done the previous exercises and it’s not your first time viewing the job descriptions of ML roles you’re interested in. If you vet the jobs that you’re apply‐ ing for, you can increase the chances of getting interviews. In my experience, this step is best used in conjunction with tailoring your resume, because if you’re not tailoring your resume, you might as well mass apply and hope you happen to apply for the jobs that match you the best. So how do you filter jobs? Remember the variety of ML roles that were introduced in Chapter 1 ? Let’s cut through the noise so that you can focus on marketing your skills to the roles that best fit your experience. Refer to the common ML job titles in Figure 1-8 : which roles do you feel suit you best? If you are most interested in a job that you don’t currently have the experience for, do you have a better idea of where to focus your learning to bridge that gap? In the skills matrix, Table 1-3 , you can see right off the bat that the role of data ana‐ lyst can have overlapping skills with the data scientist role, which in turn overlaps a lot with the role of the MLE. The good news is that with a few of these skills in your skills list, you can apply for one or more of these positions. And don’t worry—recall that for entry-level roles, as long as you have one or two of the skills listed, you’re good to go for applying to those jobs. It’s also perfectly normal for new grads to have strong skills in one pillar of ML skills but not in all, which most employers understand and welcome. Mapping your skills to the matrix is only part of the process, though, because the reality is that this matrix has to be taken with a heavy dose of “it depends.” That’s why the next section of this chapter asks you to analyze a real job posting. I’ve seen plenty of job seekers encounter this situation: “this job title is data scientist; why were the questions in the interview about data engineering (or insert something unexpected)?” Recall that an ML title depends on the company or organization plus which team the role is in plus where in the machine learning lifecycle the role is (refer back to Figure 1-3 ). As an extreme example, I’ve been through a “data scientist” interview where they did not ask any statistics or machine learning theory questions nor any data-related ques‐ tions. Instead, the interview consisted of a few rounds of LeetCode-style (coding quiz) programming questions. I wondered how they could gauge whether I would be a good ML practitioner whose core work centers around data when the questions were fully copied from a generalist software engineer loop. In hindsight, it was proba‐ bly because that role was not really responsible for training ML models at all. Because of the often-ambiguous nature of job titles, it can be difficult as a candidate to decide what topics to prepare for. Sure, you can spend time reviewing ML theory as well as grinding some coding quizzes, but your time is stretched thin, and you could be preparing for something that won’t even be asked. I’ve seen candidates rejected from jobs, not because they weren’t strong ML candi‐ dates, but rather because they were applying for the “wrong” roles. Confusingly, those roles had the same job titles as ones that the candidate would actually be suc‐ cessful at. The key is to develop the intuition for how to categorize a job title depend‐ ing on the job description and find the best roles to apply for that suit your skills. Some of these job titles show up in multiple sections, and that’s OK! Well, it’s not that OK when it causes confusion and rejections, but you’ll be able to better vet and target them by the end of this chapter. When I apply to jobs, I glance at the job title, but to ensure I’m applying to the right jobs for my skills, I do the following: • Look at the job description. • Categorize the job responsibilities; where is it in the machine learning lifecycle ( Figure 1-4 )? • Determine whether the job title and job description match up enough; for exam‐ ple, if the job title is machine learning engineer but the description makes it seem somewhat like a data engineering role (which my past experience isn’t relevant to), I will pass on the role. Polish up your resume and apply to one job. The worst they can do is ignore your application. Try it! It can be worth it to track applications so that it’s easier to remember what jobs you have applied for. If you’ve passed the resume screening and at least reached the recruiter screening, tracking those applications can help you remember to follow up, in case you don’t hear back during the time frame when they told you they’d let you know. I used to track most of my applications, but to be honest, I now think you should only track applications where you’ve at least passed the resume screening. Especially if you mass applied to any job related to ML, there’s no point in spending the addi‐ tional time to track your applications, and not tracking them won’t affect your pass rate. One scenario where you might find it useful to track your applications is if you personally plan to summarize or visualize your journey and stats later on. I do think it’s useful to keep track of who I’ve interviewed with, so I can reach out if I have more questions about the team or company. I could also reach out to them if I interview with the same company a few years later. Recall that networking is a long- term investment with long-term horizons! As for tools to track applications and interviews, I think Google Sheets, Microsoft Excel, or another simple spreadsheet tool is more than adequate. Table 2-2 is an example of how I tracked applications and interviews in Google Sheets (names are fictionalized). Table 2-2. Spreadsheet example of tracking applications and interviews After you’ve received some offers, you can then look back to see how many inter‐ views you did. It’s also nice to have a list of relevant interviewers and their emails in case you want to reach out to them a few years later. However, I’ve heard from some people that keeping track of their application-to-interview-to-offer ratio can make their mood go more down than up, so it depends on you."
      },
      {
        "section": "Additional Job Application Materials, Credentials, and FAQ"
      },
      {
        "text": "I’ve walked through the resume guide, but there still are some additional components of job applications, such as project portfolios and online certifications. This section gives some best practices and FAQs. Project portfolios are basically project examples. As a student, I had a few side projects (aka personal projects). I put the code up on GitHub and also created some figures/visualizations. GitHub is a pretty common place to host projects, but some candidates publish their project portfolios as a website, such as a Heroku site. Recall that the goal of your application and interviews is to convince the employer that you’re a good candidate for the job: you have the skills or can easily be trained for the job. For junior, entry-level, and new-graduate candidates: if you don’t yet have a lot of work experience but do have a project portfolio, it can help showcase your skills and increase the hiring manager’s and hiring team’s confidence in your abilities. But if you have plenty of work experience already, there are marginal returns to hav‐ ing a project portfolio; in interviews, employers would rather discuss your past work, case studies, technical deep dives of past projects, and so forth. You may still benefit from having a project portfolio on GitHub because much of the code and many of the models that you developed in your past job experience may be proprietary, so you might not have code samples that you can share. In that case, showcasing a personal project in a GitHub repository or contributions to open source projects would be useful. Here are some common mistakes I’ve seen in candidates’ project portfolios and how to avoid them: Not having a README or overview about the project If you’re on GitHub, follow the instructions to create one that renders. Using cliché datasets such as MNIST or widely available tutorials Many other candidates likely have the exact same code examples, and interview‐ ers can tell. Enhance common datasets with custom data that you gathered your‐ self or scrape your own. Only dumping your code, without any explanation or inline documentation Add more code comments to help your interviewer understand what they’re looking at. Having a confusing or highly nested folder structure Use your judgment to tidy things up; don’t just dump a bunch of .py scripts. The real consequences of these mistakes are that the recruiter or person filtering out candidate resumes wastes too much time trying to click through your GitHub or website to find your relevant code. They run out of time (less than one minute per resume) and simply pass on your resume. For your portfolio to make a difference and boost your application, you should make it easy to navigate and understand at a glance. For that reason, I suggest putting important visualizations on the README and clearly marking which code files the reviewer should click on. When I review resumes, I don’t place too much importance on certifications if the candidate has past ML experience or ML projects that they did on their own time (side projects). If the candidate does not have prior relevant experience, then relevant projects and project portfolios make the biggest difference. I’d recommend you build that up in parallel with earning certifications. Some certifications hold more weight than others—recall again that the goal is to set yourself apart from other job candidates—so courses that are seen as more compre‐ hensive and practical could help. Examples include the Amazon Web Services (AWS), Google Cloud Platform (GCP), and Microsoft Azure Cloud certifications. If your entire resume consists of certifications that anyone could complete in a weekend, then your resume won’t stand out. Interviewing.io analyzed data from many job candidates and found that in its data sample, putting certifications on LinkedIn had a negative impact on the perceived quality of the candidate. Their guess is that more qualified candidates would put work experience or relevant projects on their profiles and resumes while less qualified candidates who didn’t have either would fill up their profiles with certifications. Regardless, candidates have found success with certifications, especially if they come from a nontraditional educational background. Here’s a crucial tip: watch out for diminishing returns. In economics, this means that once you’ve done several more units of something, you benefit less and less from each subsequent unit. In this case, if you’ve done five certifications, it doesn’t make too much difference whether you complete three more or five more. Five certifications will look pretty much the same on a resume as eight or ten. A mistake I see entry-level candidates make is taking the same 100-level/introductory courses again and again. For example, they will take the beginner courses on Cour‐ sera, then take another similar beginner course on Udacity, and then on edX. To an interviewer, this is almost the same as if you’d taken one single beginner course since the contents of the three courses overlap so much. It doesn’t help you stand out against other candidates who have taken more advanced courses or have good portfo‐ lio projects. So once the number of online certifications you’ve taken approaches three to five, you should try to diversify your experience: • Make sure your certifications are from reputable sources; don’t list them if they seem like they were completed in a weekend. If this removes everything in your current certification list, you should continue with the following two steps. • Take certifications in more specialized fields of your interest, such as reinforce‐ ment learning or natural language processing (NLP). • Start a side project and build a project portfolio on GitHub. Table 2-3 summarizes the general decision criteria I suggest. Table 2-3. Should you keep doing online courses and certifications? The same criteria for deciding whether online certifications are useful for you apply to the question of graduate school: is the ROI enough? Master’s degrees usually require more commitment, though, so you’ll need to look at some of these additional considerations: Monetary cost Some master’s degrees are quite costly. Opportunity cost If you’re taking master’s courses full time, would you have gone further in your career if you’d started working? You’d be giving up on work experience, work progression, and potential earnings. ROI Given the monetary and opportunity costs, is it worth it? When making big deci‐ sions like getting a master’s degree, you should estimate that the degree will return more in the long run than in the short term. If you’re interested in a master’s or higher degree only to boost your ML resume, then I recommend taking a course part time. Maybe your existing resume is enough, but you’re just missing some good side projects or interview practice. However, if there are other factors that make it worthwhile, such as intellectual curiosity, then go for it! To learn more, I recommend Eugene Yan’s review of his experience doing the part- time online master of science in computer science (OMSCS) degree at Georgia Tech. Now that I’ve covered project portfolios and credentials, here are some additional FAQs about resumes. I often hear the advice to keep tech resumes to one page. In general, I agree, and I personally keep my resume to one page. However, I can see this changing depending on your situation. I’ve interviewed many candidates from Europe who had two-page resumes, and they did fine going through the resume screening. In the United States and Canada, I tend to see candidates with one-page resumes. In tech in North America, it’s not custom to include profile pictures on a resume, but I have seen that when looking over the resumes of candidates from Asia and Europe. If you are job seeking in other parts of the world, double-check with people in the industry or even online forums to see if there are expectations for resume length or information to include that I haven’t lis‐ ted here. When I was in grad school, there was a type of resume called a CV (curriculum vitae). You use a CV to apply for graduate programs, postdoctorate programs, teaching positions in academia, and the like. A CV focuses more on your research publications and tends to be lengthier; it is rarely only one page long. Some CV formats I’ve seen use paragraphs more than the bullet-point format I see in industry. If you already have a CV, you can repurpose your research responsibilities into bullet points, condense them, and rework them as a more common industry format when applying for industry jobs. Of course, it’s probably fine if you just submit a CV directly as your resume, and I’ve seen candidates successfully get interviews without modifying their academic CVs, but investing a small amount of time could increase your EPA when applying to industry jobs. When I’m reading a resume, it’s not about the length but rather the quality of the pre‐ sented information. The first page and the top and center of the first page are what the interviewer will see first. You should put your most impressive and relevant expe‐ riences there. If you have other experiences you’d like to include, you can use the less important resume “real estate.” The question you should be answering is: if the per‐ son is screening a stack of 50 resumes, and they have only 5–10 seconds per resume, how can I make sure they see my most relevant experiences in those first 5–10 seconds?” As I mentioned in Chapter 1 , I don’t think there’s enough evidence that automatic filtering will reject your resume if you happen to have two columns or one column, or you use a certain font, or you use PDF versus Microsoft Word documents, and so on. Regardless, in this book, I’m assuming that automatic ATS rejections may be pos‐ sible. Personally, I’ve used two-column PDF resumes made with LaTeX for my entire career so far and haven’t had any issues at all, even with online job sites that automat‐ ically parse my resume into text. But if you think the formatting of your resume is the only thing keeping you from getting interviews, you might have bigger things to worry about. First, let’s use the points from this chapter to see what else, apart from ATS filtering, might have kept your resume from being noticed: • Did you include the most important and ML/data-relevant information in the sections where a resume reviewer can quickly see it? • Do you have much relevant ML/data-relevant information on your resume? Have you made sure your resume includes keywords that overlap with those in the job descriptions? Are the bullet points on your resume clear? Are there typos or obvious errors on your resume? Use a resume checklist (listed earlier in the resume resources) to double-check. • Have you been trying referrals, tailoring your resume, or taking other actions that increase your EPA? That said, it is true that online forms will parse your resumes for text strings, so don’t send in a .png file or use avant-garde formatting and fonts (unless you’re applying for a niche design role, something that is beyond the scope of this book). Use a simple template linked in “Resume Resources” on page 43 or even from Google Docs and export it to a PDF. KISS (keep it simple, stupid) applies here. In summary, follow the instructions of the online application portal and craft your resume using the best practices mentioned in this chapter."
      },
      {
        "section": "Next Steps"
      },
      {
        "text": "You’ve learned how to identify the ML roles best suited for you, and you’ve created a resume that’s relevant and tailored to the type of ML job you’re aiming for. My recommendation is to browse through some more job postings. When I browse for job postings, I learn a lot from simply reading job descriptions. For example, the types of “data scientist” roles I’m interested in could be very different from the “data scientist” roles that interest another job seeker. Recall the example where a “data sci‐ entist” in one company could be responsible for data analysis rather than training ML models. For the jobs with descriptions that do interest me, I note the requirements that they have in common. Optionally, I try to create two to three tailored resumes that I can send out en masse to roles that require similar skills. The reason I have two to three versions is because one is for job descriptions that seem to be looking for people who have more software skills, and another is for job descriptions for startups where I might emphasize my startup experience. The next step is to take an honest look at your current skills and the resume you’ve constructed for the ML role(s) you’re aiming for. When you were reading through ML job descriptions, in what ways did you think you could potentially strengthen your resume? What are keywords that showed up when you browsed job postings in “Exercise 2-4” on page 44 where you think you could learn more and add to your resume? Here’s a version of the ML skills matrix ( Table 1-3 ) but with blank spaces where you can evaluate your skills. Are you interested in model training but don’t have much knowledge in ML theory, statistics, or relevant programming tools? Are there other skills that you should boost in order to fit your target ML job? Fill in Table 2-4 , aided by the checklists that follow. In the table, rate your own skill levels: 1 being low and 3 being high. Table 2-4. ML and data skills self-assessment To help guide your assessment, here is a list of questions to ask yourself: Data visualization, communication—0.5 points per checkmark: • You have built dashboards and visualizations. • You are able to choose effective graph types, such as bar versus line charts, depending on the type of visualization you are building. • You have presented data insights to nontechnical team members and stakeholders. • You are able to structure a presentation so that the information for the data is clear to an audience outside the data team. • You are able to work with product teams to identify what is a good experiment. • You are able to think deeply about user experience and how ML relates to the user experience. Data exploration, cleaning, intuition—0.5 points per checkmark: • You have explored raw data. • You have dealt with imbalanced datasets before. • You have optimized a complex and slow query before. • You are able to understand from behind the scenes how data is flowing from the source to various layers. • You can use different techniques depending on whether the data is an analytical use case or a transactional use case. • You have done data modeling before and are able to ingest and transform raw data into the form defined by the schema. Machine learning theory, statistics—0.5 points per checkmark: • You know about various ML algorithms and what types of projects to use them on. • You know how the main algorithms in your field work, beyond just importing and using them in code. • You are familiar with hypothesis testing and significance. • You are aware of ML model evaluation methods. • You have done troubleshooting on ML model issues before. • You have (at some point) understood matrix algebra and multivariable calculus and how that related to a few ML algorithms, or at least regression. Programming tools (Python, SQL, etc.)—0.75 points per checkmark: • You have trained ML models with Python-based tools or other languages or frameworks. • You have experience building scripts or apps in Python or other programming languages or frameworks. • You are familiar with SQL queries and methods such as window functions. • You have used Python libraries such as pandas or NumPy to wrangle data. Software infrastructure (Docker, Kubernetes, CI/CD, etc.)—0.75 points per checkmark: • You have done DevOps-related work before. • You have dealt with fixing slow runtimes. • You have deployed an ML model before, via a web app or other method. • You have worked with automation via tools such as Jenkins, Kubernetes, or Docker. Compare your scores to those in the ML skills matrix ( Table 1-3 ) to see where your skills roughly are. Note that this list is nonexhaustive and, depending on the job description, you may see more skills not listed here. Remember, you don’t have to get top marks in all sections since this depends on which area in the ML lifecycle that you’re interested in. However, this assessment should give you a good starting point. You should aim to get higher marks in the sections you’re interested in, or learn and prepare so that you have higher marks."
      },
      {
        "section": "Summary"
      },
      {
        "text": "This chapter focused on the ML job application step. This happens before you get interviews and is the key to getting interviews. You saw where to find jobs online and some ways to increase your chances of getting interviews via networking and refer‐ rals. You also read through some resume best practices, and hopefully, you have cre‐ ated an initial version of your resume. If you have it and feel ready, I encourage you to start applying for ML jobs even if you feel that your skills or your resume aren’t 100% perfect. Next, in the following chapters I’ll go through the various types of interviews, span‐ ning technical and behavioral interviews. First up are ML algorithms and theory, which are part of the technical interview."
      }
    ]
  },
  {
    "chapter": "CHAPTER 3",
    "title": "Technical Interview: Machine Learning Algorithms",
    "content": [
      {
        "text": "In Chapter 1 , you learned about the various steps you will go through as part of your ML interviews. In Chapter 2 , you looked at how to tie your experiences to roles of interest as well as how to craft a relevant resume. The goal of the previous chapters was to get you invited to interviews. In this chapter, I’ll focus on ML algorithms. As you recall, the interview process is illustrated in Figure 1-9 , and the ML algorithms interview is only one portion of the technical interviews; the rest, such as ML training and evaluation, coding, and so on, will be covered in subsequent chapters."
      },
      {
        "section": "Overview of the Machine Learning Algorithms Technical Interview"
      },
      {
        "text": "You’re likely to be asked ML algorithm technical questions in an interview if you’re applying for any of the following jobs: • Data scientist who builds ML models • Machine learning engineer • Applied scientist • And similar roles Recall that within the common ML job titles ( Figure 1-8 ), there are some jobs that have the responsibility of training ML models in the ML lifecycle. This chapter focu‐ ses on assessing candidates for those skills; if the job you’re aiming for focuses less on training ML models, you might get a simplified version of this type of interview, or it might be skipped completely. This interview is meant to assess your understanding of ML algorithms, especially on the theoretical side. As to how you implement the algorithms with code, I cover that in the model deployment questions in Chapter 6 and the coding/programming tech‐ nical interview in Chapter 5 . The goal for you as an interviewee is for the interviewers to confirm that you understand the underlying concepts behind ML algorithms. Roles do exist where all you have to know is how to import the library with Python, but for more advanced projects, an underlying understanding can help you custom‐ ize various ML approaches and better debug and troubleshoot models. As covered in Chapter 1 , in the three pillars of ML roles, this is the pillar of ML algorithm and data intuition, which showcases your ability to adapt (refer to Figure 1-6 ). This skill is especially important in companies that have complex ML use cases and custom-made solutions, where you might modify or combine various off-the-shelf methods or cre‐ ate something from scratch. I try to mention as many common algorithms as space allows, but there are many more techniques under the sun. Be sure to check out the linked resources to extend your learning and interview preparation! It is also important to note that, in addition to understanding the ML algorithms’ inner workings and underlying statistical methods, you need to successfully commu‐ nicate that understanding to the interviewer. Yes, I know that communication skills have been brought up many times in this book, but they are what help set you apart as a successful candidate. As a rule of thumb, it’s important to be able to explain algorithms and ML concepts at two levels: on a simple “explain like I’m five years old” level and at a deeper, tech‐ nical level, one more appropriate for a college course. A second rule of thumb is to be prepared to answer follow-up questions to these ML algorithm interview questions. This is so the interviewer knows that you didn’t just memorize and then regurgitate the answer, but that you can apply it to various real-life scenarios on the job. In this chapter, I break down technical questions on the following topics so you can easily refer to a specific question if your interview focuses on that topic: • Statistical techniques • Supervised, unsupervised, and reinforcement learning • Natural language processing (NLP) • Recommender systems • Reinforcement learning • Computer vision In technical interviews that are very structured, such as the Ama‐ zon data science initial phone screen, they will ask you clearly scoped questions, such as asking for a definition of a particular algorithm. After you answer, they will generally move on without additional follow-up questions. There are companies that mix structured questions with a free-form discussion, where the inter‐ viewer might dig deeper into your answer, and the conversation might branch out from there into your past experiences."
      },
      {
        "section": "Statistical and Foundational Techniques"
      },
      {
        "text": "Statistical techniques are used in every data role, and these techniques are the foun‐ dations for ML projects. Hence, in ML interviews, you will most likely have questions that cover this topic. Statistical techniques help build baseline models to compare more costly models and algorithms against or help discover if there is enough mean‐ ingful data in the first place to build ML models. For the purposes of this book, I will be placing the foundational regression tech‐ niques in this section, as well as various techniques for training and improving ML models. In short, these are (1) foundational techniques and (2) methods used during model training, such as training splits, regularization, and so on. These concepts are foundational knowledge for any type of ML algorithms that will be mentioned later as well as foundations for ML interview questions. This section covers the basics of statistical techniques for those who are unsure whether they have sufficient background knowledge in this area. Feel free to skip the subsections if you already have expertise in any of these areas. Regardless of your expertise, I’ve highlighted specific advice for ML interviews in the tip boxes to help you apply your knowledge of each ML area and excel in your interviews. To further supplement your knowledge on statistical and foundational techniques beyond the summaries I’ve provided in this book, I recommend the following resources: • The Elements of Statistical Learning by Trevor Hastie et al. • An Introduction to Statistical Learning with Applications in Python by Gareth James et al. • Courses on Coursera by DeepLearning.AI and Andrew Ng; this resource is also useful for all following subtopics of ML (I won’t repeatedly link their courses— since they sometimes change and update—in the following sections). • Introduction to Machine Learning Interviews by Chip Huyen has additional questions for overall ML interviews which can be referenced for most sections in this chapter. Refer back to this section for reference material when preparing for interviews. Now, let’s jump in. Here’s an overview of one of the foundations of ML algorithms—variables—and a simple example of fitting a model. Let’s say that you have a dataset about apples, with the weight and height of each apple. You also have a list of past sales prices of each apple. With the list of apple weights, heights, and past sales prices, you want to guess the sales price of new apples, before they are sold. For the sake of this example, ignore big grocery chains automati‐ cally calculating a price, but let’s say you’re selling as a hobby to friends and family, or maybe you’re running a farm that a grandparent left you. So you are making use of the weight and height of each single new apple to predict its price. Weight and height are fixed observations at that point in time (an apple can’t be both 100 grams and 150 grams at the same time). Now, to connect all these concepts, let’s add in some terminology. Variables refer to everything that is being taken into account in your model of how apple prices are cal‐ culated. So the variables in this case include weight, height, and price. Within these variables, you know the weight and height of each new apple, and they are fixed at that point in time. So the weight and height are independent variables. Then, you have another variable, price, that you’d like to predict for new apples prior to know‐ ing the correct answer before selling them. The predicted price depends on the height and weight of the new apple. For example, heavier and taller apples sell for more money. Thus, price is a dependent variable (shown in Table 3-1 ). Table 3-1. Examples of independent and dependent variables The concepts of independent and dependent variables are tried and true, but the ter‐ minology might not be. In different fields, you may have come across the terms listed in Table 3-2 , although they may differ from industry to industry or from textbook to textbook. During your interview, make sure you and the interviewer aren’t crossing wires due to terminology, and double-check with your interviewer if you sense that you’re using a different term to refer to the same thing. Knowing the most common terms can help you use them appropriately in your interviews in various fields. Table 3-2. Synonyms of independent and dependent variables Models are a way of using past data points to describe “the way the world works,” or, in other words, a way of finding patterns and connections with past information. The apples example from the previous section uses a model that describes the way pricing works. The model is something that knows the “truth”—even if it’s not the full truth but rather our best attempt to approximate the truth. Thus, the model can be used to predict our best approximation of future data points. This applies for all “models” in ML models. Recommender-system models seek to predict what a user will like or click on when visiting a website. Convolutional neural networks (CNNs) for image recognition “learn” a model of what various pixels represent: is this cluster and layout of pixels a cat or a dog? Just as for independent and dependent variables, it is important to have a shared defi‐ nition for “model” to prevent miscommunication during an interview, such as con‐ fusing algorithms with models. The model is the outcome of having run and fit an ML algorithm. I wanted to make sure I included regression models. I’m glad that I learned the detailed ins and outs of linear and logistic regression, even calculating them by hand (a requirement for the second-year statistics course I was taking as part of an eco‐ nomics major at university). This knowledge has compounded and helped me under‐ stand the new ML algorithms I’ve encountered as well as how to apply them in practice. All of my learning stemmed from understanding these entry-level concepts, so I highly recommend not shying away from learning the mathematics of regression models. Again, feel free to skip this section if you already have expertise in this area. Let’s use the apple example from an earlier section in a graph. For simplicity and to squeeze it onto a two-dimensional graph, let’s use just one independent variable, weight , to predict the dependent variable, price . Each dot on the graph in Figure 3-1 represents a data point from past sales, so you already know the sale prices for them. For example, the dot with a callout on the graph weighs 80 grams (its intersect on the x-axis) and sold for $1 (its intersect on the y-axis). Note that this is a simple example; most usage of linear regression will have multiple independent variables (“multivaria‐ ble”) and if visualized, will be a line in an N -dimensional space, where N = number of variables + 1 (when there is one output variable). In addition, this example has one dependent variable; when there are multiple dependent/output variables, the regres‐ sion task is referred to as being multivariate . Note that multivariate is separate from the “multivariable” concept mentioned earlier. Figure 3-1. Data points to be used for linear regression. The next step in linear regression is fitting the titular “line” to the data points. Behind the scenes, software tools like Python, Stata, IBM SPSS, SAS, MATLAB, and the like will calculate a “line of best fit.” According to the definition of a model given previ‐ ously in this section, this line is the model , which is the best approximation of the truth with the data points that you have. Starting with an initial line, the software will calculate the residual : the y-axis distance between a data point and the line, as illus‐ trated in Figure 3-2 . Colloquially, the residual is also referred to as the residual error . Figure 3-2. Fitting the line of best fit in linear regression; the line is iterated on until the residuals are as small as possible. All the residuals are squared so that predictions above and the line don’t cancel each other out due to having opposite signs (positive, negative). The goal is that the sum of the residuals is as small as possible since if you have a line that is drastically far away from the data points, that means the line isn’t fitting well to as many data points as possible and as correctly as possible. Mathematically, a common technique to tell how well the line is fitting is the process called least squares . Achieving least squares means finding the line that results in the smallest sum of squared residuals, which in turn means you have the “line of best fit”: the line is fitting the data points with least distance from the data points overall, as shown in Figure 3-3 . Figure 3-3. Least squares and terminology; y represents observed data points, and ŷ (y- hat) represents the predicted/estimated values. The end result is a line that has the smallest sum of least squares to the data points, as illustrated in Figure 3-4 . Figure 3-4. The resulting line of best fit with least squares from the data in Figure 3-1 . Going forward, you can use this “line of best fit” as a model to predict new apple pri‐ ces! You can plug the apple weight into the line (in equation form) to get a numerical value for the predicted price. This is one of the most basic ways of calculating a model from data points, but it has the same pattern as more in-depth ML models and algo‐ rithms that are covered in the next chapter. Namely, you’ll initialize a line (you don’t know if this is the best model yet) and calculate the residuals, or how well it fits. Next, you’ll change the line by tilting it a little—mathematically, this is called updating coef‐ ficients or weights— and calculate the residuals again, as illustrated in Figure 3-2 . This updating process is called training , which is where the commonly used phrase “training/to train an ML model” comes from. If the sum of the squared residuals is getting smaller, then you are on the right track. When you can’t make the squared residuals any smaller, you’ve achieved least squares, and that’s how you can say the line is your best approximation with this dataset (as illustrated in Figure 3-4 ). It’s like that game where there’s an item hidden in the room, and as you walk around the room trying to find it, your friend says “hot” if you’re getting closer and “cold” when you’re walking farther away. You want to walk toward hotter and hotter areas in the room, until you reach the final position. In Chapter 4 , I’ll walk through ways to evaluate models via error terms such as mean squared error (MSE), root mean square error (RMSE), and more, which are very sim‐ ilar concepts to residuals. The main difference here is that residuals are the difference between past observation data and model estimations while errors are the difference between model estimations and actual data previously unseen by the model. In other words, errors are the differences after applying the model to previously unseen data in order to evaluate model performance. To sum up, when using supervised machine learning such as the simple linear regression example in the previous section, you’ll generally start with a dataset and want the ML algorithm to learn a model of how things work. You then will use the model to calculate the values of dependent variables, such as predicting how much apples will sell for before they are actually sold. In other words, you have a dataset of past data points and, of course, no future data points. When the ML model is being trained, it’s learning to “fit” the data that you currently have. There are some issues that could arise with model training when the model is used in the real world. For one, there will always be outliers or changing events in the real world. One example is in financial predictions with ML: the market could swing suddenly to a bear (downturn) market, and the model we’ve trained with financial data in a bull (upswing) market will produce horrible and wildly inaccurate predictions. Another example is that the dataset you have isn’t representative enough of the behaviors of the real world. In the apples example from the previous section, you assume that with the weight and height data of the apples, you can predict the sell price of new apples. But what if the data you have on hand isn’t enough, and apple variants like Fuji or Honeycrisp (one of my favorites) sell for more? You didn’t have each apple’s variant name tracked in your dataset, so then your model may be incorrect once you put it to the test. But for now, you have only the current dataset. To make the most of it, you need to keep some of the data you have for testing purposes. What this means is that you can break out 80% of the apple data points to use for model training and then save 20% of the apple data points to run the trained model predictions on. The 80% the model is trained on is called the training set (sometimes referred to as the train set ), and the 20% of data that is unseen by the model during the training phase is called the test set . This mimics the real-world scenario of running the model to predict new data points; the test set serves that purpose. In many cases, you might even split the data into three chunks: 80% as the training dataset, 10% as the validation (holdout) dataset, and another 10% as the test dataset ( Figure 3-5 ). The validation set allows you to monitor the model’s performance during the train‐ ing process without “formally” evaluating it, and it enables you to diagnose weak spots of the model and tune its parameters. The test set, as previously mentioned, was unseen by the model during the training process and thus is used to formally evaluate the model performance, mimicking a real-world environment as much as possible. Of course, having a test and validation set isn’t infallible, which brings us to more robust techniques and the concepts of model overfitting and underfitting. Figure 3-5. Training, validation, and test set splits. For interview questions on training and test sets, make sure you can name common ways to augment the simpler splits, such as using cross-validation : splitting up data into smaller chunks and rotating through them as training sets. There are many reasons a model may not perform well on real-world data (or even the validation or test set). A common starting point is addressing overfitting or underfitting. Underfitting is when the model isn’t fitting well. This might mean that the model isn’t able to capture the relationship between the dataset’s independent variables (e.g., weight, height, etc.) and the dependent variables (e.g., price). Conse‐ quently, some ways to reduce underfitting are related to helping the model learn more nuances or patterns during the training process. For example, adding more variables, or model features, such as apple variant or age of the apple, could help the model learn more patterns from the training data and potentially reduce underfitting. A second way to reduce underfitting is to increase the number of iterations the model trains for before training is stopped . Overfitting is when a model fits the training data too closely and very specifically, perhaps finding patterns that happen to be in the training set but not elsewhere. A simplified example is that the training data just so happens to have a lot of apples that are disproportionately expensive despite their weight (e.g., Sekai Ichi apples ). The model learned from that data and overfit to it, therefore making incorrect predictions that are overpriced for cheaper apple variants. Simply put, the model is overmemo‐ rizing the training data and unable to generalize to new data points. There are many techniques to make the model generalize better, such as adding more training data, data augmentation, or regularization. I’ll cover the details of regularization next. Regularization is a technique used to reduce overfitting of ML models. Generally, regularization will create a damper on model weights/coefficient. By this point, you likely know what I’m going to do—which is to bring up the apples again! Apples are my favorite fruit, which is probably why I use the example so often. So let’s say the model has learned to weigh “weight of apple” more heavily (accidental pun, but model “weights” is legitimate terminology); then the weight of the apple is mathe‐ matically increasing the results of the ML model’s prediction of the price by a rela‐ tively high positive value. If you can dampen the amount by which the weight of the apple increases the model’s predictions of the price, via regularization, that can make the model generalize more and take other variables into account more evenly. The variance bias trade-off is a common topic in ML interviews. When applying ML model improvement techniques such as regularization, it is important to consider the trade-off between fixing for bias versus variance. Bias refers to the overall inaccuracy of the model and can often be caused by an oversimplified (underfit) model. Variance comes from overfitting, when the model has learned too specifically from the training set. One way to remember why this is called “variance” is that the term refers to the variability of the model: the model is overfit to specific points or traits, so the model is very sensitive to different data points, causing fluctuation and variability. Regularization might cause a model to reduce its variance but might inadvertently increase bias, so that’s a reason to be cautious and test various model-improvement techniques. Now that I’ve covered various statistical and ML techniques at a higher level, let’s look at some sample questions. Here, I will dive into the details of common interview questions that stem from the concepts covered in this section. These details may not have been previously addressed, so my hope is that these sample questions also serve to explain the new concepts. Example answer L1 regularization , also known as lasso regularization , is a type of regularization that shrinks model parameters toward zero. L2 regularization (also known as ridge regularization ) adds a penalty term to the objective function that is propor‐ tional to the square of the coefficients of the model. This penalty term shrinks the coefficients toward zero, but unlike L1 (lasso) regularization, it does not make any of the coefficients exactly equal to zero. L2 regularization can help reduce overfitting and improve the stability of the model by keeping coefficients from becoming too large. Both L1 and L2 regulari‐ zation are commonly used to prevent overfitting and improve the generalization of ML models. Interview questions on model overfitting and underfitting may lead to follow-up questions. For example, if you bring up L1 and L2 regularization, the interviewer might ask, “What other types of reg‐ ularization could work?” In that case, you could bring up elastic net , which is a combination of L1 and L2 techniques. Or for the overfitting case, ensemble techniques can also help (refer to “Inter‐ view question 3-3: Explain boosting and bagging and what they can help with.” on page 76 ). Example answer Imbalanced datasets in ML refer to datasets in which some classes or categories outweigh others. Techniques to deal with imbalanced datasets include data aug‐ mentation, oversampling, undersampling, ensemble methods, and so on: Data augmentation Data augmentation involves generating more examples for the ML model to train on, such as rotating images so that the dataset includes images of humans turned upside down as well as the normal upright image orienta‐ tion. Without data augmentation, the model might not be able to correctly recognize images of humans who are laying sideways or doing headstands since the data is imbalanced toward humans in an upright pose. Oversampling Oversampling is a technique to increase the number of data points of a minority class via synthetic generation. As an example, SMOTE (synthetic minority oversampling technique) uses the feature vectors of the minority classes to generate synthetic data points that are located between real data points and their k-nearest neighbors. This could synthetically increase the size of the minority class(es) and improve the performance of the ML model trained on a dataset with oversampling treatment. Undersampling Undersampling does the opposite: it reduces examples from the majority class to balance the number of data points of the majority class and minority class(es). Oversampling is generally preferred in practice since undersam‐ pling may cause useful data to be discarded, which is exacerbated when the dataset is already small. Ensemble methods Ensemble methods can also be used to increase model performance when dealing with an imbalanced dataset. Each model in the ensemble can be trained on a different subset of the data and can help learn the nuances of each class better. When answering ML interview questions, take a second to confirm the scope of the question. In other words, if the question is asking only for a definition of logistic regression, don’t go on a tangent about various other techniques. If the question is open-ended, you can confirm whether the interviewer is asking for something specific. Example answer Bagging and boosting are ensemble techniques used to improve the performance of ML models: Bagging Bagging trains multiple models on different subsets of the training data and combines their predictions to make a final prediction. Boosting Boosting trains a series of models where each model tries to correct the mis‐ takes made by the previous model. The final prediction is made by all the models. Ensemble techniques can help with a variety of issues encountered during ML training. For example, they can help with imbalanced data and reduce overfitting. See Chapter 4 for more in-depth questions concerning model evaluation."
      },
      {
        "section": "Supervised, Unsupervised, and Reinforcement Learning"
      },
      {
        "text": "In ML roles, knowing when and what to pick from each family of techniques— including supervised, unsupervised, or reinforcement learning—is an essential skill. In my previous jobs, I’ve used supervised learning to prevent fraud and customer churn, but at other times, I used unsupervised learning like anomaly detection for the same problem, depending on the data and situation. Sometimes (more often, as you grow more senior in your ML career), you might even create an ML pipeline with both supervised and unsupervised learning. In your reinforcement learning pipeline, you might use supervised learning in a previous step to label features. Understanding the underlying mechanics can help you adapt to new situations when using different techniques might be more effective than sticking to what is convenient. Therefore, in interviews there are often questions about supervised versus unsuper‐ vised learning. Reinforcement learning (RL) is considered a somewhat advanced topic and may not be touched on in many interviews. However, I’ve been asked about it in a nontrivial number of interviews because of the growth of RL use for industry applications such as in conjunction with recommender systems—although my past work experience in RL may have prompted the interviewers to ask me about it. As I mentioned in Chapter 2 , if something’s on your resume, it’s fair game to discuss in the interview! For a more comprehensive overview of RL, see “Reinforcement Learn‐ ing Algorithms” on page 101 . Regardless of what types of ML roles you’re interviewing for, knowledge about supervised and unsupervised learning is a must. Brush up on reinforcement learning concepts afterward, in terms of priority. This section covers the basics of labeled data, supervised learning, unsupervised learning, semi- and self-supervised learning, and reinforcement learning, those who are unsure whether they have the background knowledge in this area. Feel free to skip the subsections if you already have expertise in any of these areas. Regardless of your expertise, I’ve highlighted specific advice for ML interviews in the tip boxes to help you apply your knowledge of each ML area and excel in your interviews. To further supplement your knowledge on supervised and unsupervised ML tech‐ niques, beyond the summaries I’ve provided in this book, I recommend the following resource: • The Elements of Statistical Learning by Trevor Hastie, Robert Tibshirani, and Jer‐ ome Friedman Refer back to this section for reference material when preparing for interviews. Returning to our apple dataset from “Summarizing Independent and Dependent Variables,” you have the data points for how much apples sold for in the past. The price is also the dependent variable in “Summarizing Linear Regression.” The fact that you do have labels for the dataset means that the ML tasks you were doing pre‐ viously were with labeled data. An example of unlabeled data is when you have the prices and weights of the apples but not the apple variants, yet you try to deduce commonalities within different variants of apples. Because you don’t initially have the correct or expected “label”—in this case, the apple variant—you would be using unla‐ beled data and conducting unsupervised learning. Building on the concept of labeled and unlabeled data, let’s move on to supervised learning. Supervised learning is the first type of machine learning as defined by its use of labeled data, illustrated in Figure 3-6 . Supervised learning uses correct or expected outcomes of the past to predict the dependent variables for new or future data points. The example of using apple weight, variant, and so on to predict sales prices for new apples is supervised learning. Supervised learning can be broken down into two main categories: regression and classification. Figure 3-6. Overview of machine learning families (simplified for understanding). In regression tasks, the dependent/output variable is a continuous value. For example, predicting stock prices, housing prices, or weather (temperature) produces continu‐ ous values. Classification is a type of supervised learning in which the dependent/ output variable is categorical—that is, it is put into a category, such as “it’s a dog” or “it’s a cat.” Classification examples include detecting whether something is or isn’t spam, using image recognition such as tagging animal types in a picture, and so on. It is possible to mix categorical data with continuous data via techniques such as one- hot encoding . For example, if we’re trying to classify if there is a dog or a cat in an image, an image that has a dog will be encoded with 1 for the “dog” category and 0 for the “cat” category. Think of it like a Boolean (True/False) representation of the data for each category. Then you can mix these numerical encodings (0 or 1) with datasets with continuous values. Unsupervised learning is training a model with unlabeled data: when you do not have the “labels” available (the labels being the correct or expected values that you are looking for). You’d likely use unsupervised learning to find patterns, commonalities,"
      }
    ]
  }
]